# MySQL 原理

# 初识 MySQL

MySQL 是种关系型数据库管理系统，用于存储和管理数据。MySQL 支持各种操作系统，不同平台的实现，目录结构和使用方式稍有不同，这里以类 UNIX 平台为例进行学习。

MySQL 基于 Client-Server 结构，服务端程序直接与存储的数据交互，接收请求，读写数据并进行相应的计算和处理，然后返回。客户端程序只是向服务端发送请求，同时接收和处理返回结果。

MySQL 的服务端程序和客户端程序都是计算机内的进程，代表服务端程序的进程，称为 MySQL 实例。

## 启动连接

MySQL 安装目录 *bin* 子目录，包含许多可执行文件，MySQL 的大多功能都可以通过这些文件进行使用。这里学习启动 MySQL 服务端/客户端的可执行文件。

### 启动服务器

**mysqld**

*mysqld* 可执行文件表示 MySQL 服务端程序，执行它启动一个 MySQL 实例。

**mysqld_safe**

*mysqld_safe* 是启动脚本，它会调用 *mysqld*，然后持续监控服务端程序的运行状态，如果发生错误，它能协助重启服务端程序。另外，它还会把出错信息和诊断信息写到错误日志。

错误日志是以 *.err* 为拓展名的文件，位于 MySQL 数据目录。

**mysql.server**

*mysql.server* 是启动脚本，它会调用 *mysqld_safe*，参数 *start* 表示启动服务端程序。

```
mysql.server start
```

参数 *stop* 表示关闭正在运行的服务端程序。

```
mysql.server stop
```

> *mysql.server* 其实是一个链接文件，对应的实际文件是 *BASE_DIR/support-files/mysql.server*。

**mysqld.multi**

*mysqld.multi* 脚本用于启动/关闭多个 MySQL 实例，或者报告它们的运行状态

### 客户端连接

**mysql**

*mysql* 表示 MySQL 客户端程序，用于发出请求和接收响应。

```
mysql -h主机地址 -P端口 -u用户名 -p密码
```

参数 *-h* 指定 MySQL 实例的主机地址，实例在本机可省。参数 *-P* 指定 MySQL 实例的端口，默认 3306。通常，短参和值之间可以有任意空白，但是 *-p* 不支持，因为密码可能以空白开头。

连接成功后，如果想断开连接并关闭客户端，可以使用 *quit* 或 *exit* 命令。

## 通信过程

### C/S 通信方式

MySQL 的客户端和服务端之间的交互，就是进程间的通信。进程通信最常见的方式是 TCP/IP 协议，这也是最常用的方式，只有这种方式需要 *-h* 和 *-P* 参数定位服务端。

对于 Windows 平台的实现，还支持命令管道和共享内存的通信方式，类 UNIX 平台的实现，还支持 UNIX 域套接字通信方式。

### 请求处理过程

以查询请求为例，说明 MySQL 服务端处理客户端请求的过程。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-88dbcb5e.jpg)

**管理连接**

MySQL 支持同时处理多个客户端连接，每个连接使用一个线程维护，并且，客户端断开连接后，维护连接的线程不会销毁，而是保存起来等待处理下个连接。MySQL 使用线程池处理客户端连接。因为线程池的大小有限，必要时 MySQL 会拒绝客户端的连接请求。

客户端发出的连接请求，需要携带主机、用户名、密码等信息，服务端进行认证，认证失败则拒绝连接，认证成功则会为这个连接维护一堆数据，比如 Session 系统变量。

连接成功之后，服务端线程如果长时间没有收到客户端的请求，将自动断开连接。

**查询缓存**

MySQL 基于文本缓存返回成功的查询请求，查询缓存全局共享。每收到一个查询请求，首先都会尝试从缓存查找结果。请求与缓存即使含义相同，只要有任何字符差异，比如空格、注释、大小写，都会导致不命中缓存。如果有使用某些系统函数、用户自定义变量、函数，则无法使用查询缓存，返回的结果也不会被缓存，因为这些元素的值动态变化。

MySQL 缓存机制会监视涉及的表，如果表的结构或数据被修改，那么这个表相关的查询缓存都会失效。

> 查询缓存虽然可以提升性能，但是维护这块缓存也带来一些消耗，从 MySQL 5.7.20 开始，就不推荐使用查询缓存，MySQL 8.0 甚至直接移除查询缓存。

**语法解析**

缓存没有命中，就要进入查询阶段。查询请求本质就是文本，主要元素是  SQL 命令。服务端在此对 SQL 语句进行分析，检查语法是否正确，再把涉及的表、查询条件提取出来，放到内部的数据结构，以供后续使用。

**查询优化**

服务端已经得到必要的信息，比如要查找的表和列、搜索条件，根据这些足以精确查找数据。不过，MySQL 认为用户编写的 SQL 语句在 MySQL 的执行效率不一定高，需要进行一些优化，比如把外连接转换为内连接、子查询转换为连接、表达式简化。

优化结果是一个执行计划，计划表明应该使用哪些索引执行查询，以及表间的连接顺序。使用 `explain` 命令可以查看某个查询语句的执行计划。

**调用存储引擎**

为了管理方便，MySQL 把服务端分为 Server 层和存储引擎，前面的步骤都在 Server 层执行，现在，Server 根据执行计划，调用存储引擎的接口，获取数据，然后返回给客户端。

连接管理、查询缓存、语法解析、查询优化都属于 Server 层的动作，存储引擎负责读写数据。Server 层和存储引擎的交互，常以记录为单位。当然，记录不会直接返回给客户端，而是放在一个缓冲区，等到缓冲区满后，再执行发送。缓冲区的大小由系统变量 `net_buffer_length` 控制。

## 存储引擎

MySQL 把数据的存储和提取操作封装到"存储引擎"模块。数据表由一行一行的记录组成，这是逻辑概念，底层如何组织数据，则由存储引擎决定。MySQL 提供许多存储引擎实现，使用不同存储引擎的表，存储结构不同，支持的功能也不同，比如 InnoDB 表支持事务、外键、行级锁，这些功能 MyISAM 表都没有。

存储引擎都基于相同的接口设计，所以不论使用哪种存储引擎，Server 层的调用方式不变。

MySQL 从 5.5.5 开始以 InnoDB 作为默认存储引擎，之前一直都是 MyISAM。

**相关命令**

查看可用的存储引擎列表。

```
show engines;
```

查看默认存储引擎。

```
show variables like 'default_storage_engine';
```

创建表时指定存储引擎。

```
create table 表名 (
	...
) engine = 存储引擎;
```

修改已存在表的存储引擎。

```
alter table 表名 engine = 存储引擎;
```

# MySQL 配置

MySQL 的服务端和客户端都有许多可配置参数，用于修改程序的运行逻辑。比如，MySQL 服务端可以修改最大客户端连接数，默认 151。这些参数，可以在执行启动脚本时设置，有命令行、配置文件两种设置方式。

## 命令行

使用启动脚本的命令行参数设置 MySQL 参数，有两种格式，长格式 `--option=value` 中间不能有空白字符，短格式 `-option value` 的名和值之间可以有任意空白字符，密码 `-p` 除外。

示例，设置 MyISAM 作为默认存储引擎。

```
mysql.server start --default_storage_engine=MyISAM;
```

示例，设置禁用 TCP/IP 网络通信。

```
mysql.server start --skip-networking;
```

## 配置文件

命令行参数只影响此次运行，每次启动都需要添加相同的参数，否则又会使用默认配置，比较麻烦。MySQL 启动时会加载一些配置文件，这些文件包含 MySQL 参数。可以修改配置文件，以持久地配置参数。

**配置文件的路径**

执行 MySQL 启动脚本，将依次从以下路径加载配置文件。

| 路径                  | 说明                                                         |
| --------------------- | ------------------------------------------------------------ |
| *default-file*        | 这是一个命令行参数，指定只加载某个配置文件，忽略其它配置文件。 |
| *ect/my.cnf*          |                                                              |
| *etc/mysql/my.cnf*    |                                                              |
| *SYSCONFDIR/my.cnf*   | SYSCONFDIR 是用 CMake 构建 MySQL 时，SYSCONFDIR 参数指定的目录。 |
| *$MYSQL_HOME/my.cnf*  | 只有服务端相关的参数。MYSQL_HOME 是环境变量，使用 *mysqld_safe* 脚本启动服务，如果没有配置 SYSCONFDIR，它默认是 MySQL 的安装目录。 |
| *defaults-extra-file* | 这是一个命令行参数，指定额外的配置文件的路径。               |
| *~/.my.conf*          |                                                              |
| *~/.mylogin.cnf*      | 只有客户端相关的参数。                                       |

**配置文件的格式**

配置文件的 MySQL 参数被分为多个组，每个组以 `[组名]` 开始，如下所示。

```
[server]
option1 = value1
option2 = value2
...

[mysqld]
option3 = value3
option4 = value4
...
```

每个 MySQL 参数独占一行，等号 `=` 周围可以有空白字符，还能使用 `#` 添加注释。

每个分组，只会被同名的启动脚本加载，比如，*mysql.server* 加载 `[mysql.server]` 的内容。不过，有两个分组比较特别：

* `[server]` 分组的参数作用于所有的服务端程序。
* `[client]` 分组的参数作用于所有的客户端程序。

因为 *mysql.server* 调用 *mysqld_safe*，而 *mysqld_safe* 调用 *mysqld*，所以它们都会加载 `[mysqld]` 分组。

还能在分组名的尾部追加 MySQL 版本号，限定这个分组只在特定版本生效，比如 `[server-5.7]`。

**配置分组的优先级**

不同配置文件，按照加载顺序，后面文件的参数的优先级更高。相同配置文件，不同分组按照上下顺序，后面分组的参数的优先级更高。

另外，配置文件的优先级始终低于命令行，而且，有的启动参数只能在命令行设置，比如 defaults-file。

**限制单个配置文件**

使用命令行参数 *default-file* 指定某个配置文件的路径，脚本将只加载这个配置文件，跳过其它配置文件，如果文件不存在或无法访问，将会发生错误。

# MySQL 变量

## 系统变量

MySQL 程序运行时会使用许多变量，它们决定着程序的运行，称为系统变量。

**系统变量的作用域**

每个客户端连接可能想有不同的行为，为此，系统变量有作用范围之分：

* `GLOBAL`：决定服务端的整体操作。
* `SESSION`：决定客户端连接的操作。

服务端程序启动时，把所有全局变量初始化为默认值。服务端会为每个客户端连接维护一组会话变量，这些会话变量在建立连接时使用相应的全局变量进行初始化。

并非所有系统变量都有 `GLOBAL` 和 `SESSION` 作用域，有的变量只有 `GLOBAL`，比如 max_connections，而有的变量只有 `SESSION`，比如 insert_id，它是某个 auto_increment 列的初始值。

**设置系统变量**

系统变量都有默认值，可以使用 MySQL 参数（命令行，或配置文件）修改变量的默认值，大多系统变量还支持运行时修改。系统变量和 MySQL 参数不是对应关系，有的系统变量只读，有的 MySQL 参数也不影响系统变量。

```
set [global|session] 变量 = 值
```

```
set [@@(global|session).]变量 = 值
```

修改全局系统变量的值之后，新值将作用于后面建立的客户端连接，已有连接的会话变量不会有改变。若要影响当前连接，只能通过修改它的会话变量。

**查看系统变量**

默认查看会话范围，除非指定 `GLOBAL` 或这个变量没有会话范围。

```
show [global|session] variables like '匹配模式';
```

## 状态变量

状态变量类似系统变量，它的作用是描述服务端程序当前的运行状态，可以把它看作只读的系统变量。而且，状态变量也有 `GLOBAL` 和 `SESSION` 作用范围。

```
show [global|session] status like '匹配模式';
```

# 字符集和比较规则

文本数据必须指定其使用的字符集，否则只是没有意义的二进制编码。比较规则用于排序数据等用途，每种字符集都有多种比较规则，有的比较规则不区分大小写，有的比较直接使用二进制编码。

## 数据的字符集

查看 MySQL 可用的字符集，任何与"字符集"相关的命令，基本都可以使用"charset"替换"character set"。 

```
show (character set|charset) like '匹配模式';
```

每种字符集都有多种比较规则，在 MySQL，比较规则的名字都由下划线连接的 3 个部分组成，第一个部分表示对应的字符集，第二个部分是规则所用的语言，第三个部分表示是否区分语言中的重音、大小写等。

| 后缀（第三部分） | 说明             |
| ---------------- | ---------------- |
| _ai              | 不区分重音       |
| _as              | 区分重音         |
| _ci              | 不区分大小写     |
| _cs              | 区分大小写       |
| _bin             | 以二进制方式比较 |

查看 MySQL 可用的比较规则。

```
show collation like '匹配模式';
```

## 分级的字符集

MySQL 可在 4 个层级设置字符集和比较规则：服务器、数据库、表，列。

**服务器级别**

MySQL 提供两个系统变量，表示服务器级别的字符集和比较规则。

| 系统变量             | 说明     |
| -------------------- | -------- |
| character_set_server | 字符集   |
| collation_server     | 比较规则 |

**数据库级别**

创建数据库时指定字符集和比较规则，默认使用服务器级别的设置。

```
create database 数据库名
	[default] charset 字符集
	[collate 比较规则];
```

修改已有数据库的字符集和比较规则。

```
alter database 数据库名
	[[default] charset 字符集名]
	[collate 比较规则名];
```

可以使用两个只读的系统变量，查看当前连接的数据库的字符集和比较规则。

| 系统变量               | 说明     |
| ---------------------- | -------- |
| character_set_database | 字符集   |
| collation_database     | 比较规则 |

**表级别**

创建表时指定字符集和比较规则，默认使用数据库级别的设置。

```
create table 表名
	[[default] charset 字符集名]
	[collate 比较规则名];
```

修改已有表的字符集和比较规则。

```
alter table 表名
	[[default] charset 字符集名]
	[collate 比较规则名];
```

**列级别**

创建表时指定列的字符集和比较规则，默认使用表级别的设置。

```
create table 表名 (
	列名 字符串类型 [charset 字符集名] [collate 比较规则名]),
	其它列...
);
```

修改已有表的列的字符集和比较规则。

```
alter table 表名 modify 列名 字符串类型 [charset 字符集名] [collate 比较规则名]);
```

## 通信的字符集

客户端发送给服务端的数据，以及服务端返回给客户端的数据，其实都是文本，需要进行编码、解码，甚至转码。

**建立网络连接**

MySQL 客户端通常使用与操作系统一致的字符集。对于 UNIX 平台，LC_ALL、LC_CTYPE、LANG 这 3 个环境变量决定着操作系统使用哪种字符集，优先级依次递减，如果都没有配置，系统就使用默认的字符集。

MySQL 客户端向服务端请求连接时，把字符集和用户名、密码等信息一同发出。服务端收到连接请求，根据客户端的字符集，为这个连接维护 3 个可写的会话变量：

* character_set_client：服务端解码请求时使用的字符集。
* character_set_connection：服务端把请求转码为这个字符集再进行处理。
* character_set_results：服务端向客户端返回数据时使用的字符集。

以下命令为这三个变量统一设置相同的值，这是一个语法糖。

```
set names 字符集名;
```

**客户端的编码**

客户端接收用户的输入，使用初始设置的字符集进行编码，然后发出。

**服务端的处理**

服务端收到请求，按照 MySQL 协议进行解析，使用 character_set_client 解码请求语句，得到请求原语。然后把数据转码为 character_set_connection 进行处理。中途转码，因为相同数据在不同的字符集和比较规则可能有不同的结果。

值和列进行比较，如果两边的字符集不同，将把值转码为列的字符集，并使用列的比较规则进行比较。

**返回响应结果**

计算出结果，使用 character_set_results 对其转码，然后返回给客户端。类 UNIX 平台，*mysql* 脚本会直接打印返回结果，如果是自制的客户端程序，还能做更多处理，至少可以转码。

# InnoDB 记录行格式

存储引擎 InnoDB 把数据存到磁盘，记录在磁盘的存储格式称为行格式。InnoDB 支持 4 种行格式：COMPACT、REDUNDANT、DYNAMIC、COMPRESSED。其它存储引擎也有使用行格式，它们的实现大同小异。

创建表时指定行格式。

```
create table 表名 (
	...
) row_format = 行格式;
```

修改已有表的行格式。

```
alter table 表名 row_format = 行格式;
```

## COMPACT

对于 COMPACT 行格式，可以把它的结构分为两个部分：额外信息、真实数据。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-dfb7387d.png)

**变长字段长度列表**

MySQL 支持变长数据类型，比如 `varchar(M)`，这种字段的大小不固定，所以行格式需要记录它们真正占用的空间大小。变长字段长度列表，按照逆序保存各个变长字段的字节数。

每个长度使用 1 或 2 个字节，如果字段可能达到的最大长度超过 255 字节，并且真实数据超过 127 字节，就使用两个字节，否则使用 1 个字节。

如果字段的内容特别大，COMPACT 将把这个字段的部分数据存到溢出页，长度列表只记录本地的数据的长度。

如果没有变长类型字段，或者所有列的值都是 `null`，行格式就不会有变长字段长度列表。

**NULL 值列表**

COMPACT 使用 NULL 值列表标记值为 `null` 的字段，真实数据处则不必存 `null` 值，节省空间。NULL 值列表的设置过程可以分为以下 3 步：

* 如果没有允许值为 `null` 的列，行格式不会有 NULL 值列表。
* 每个允许值为 `null` 的列，都对应一个二进制位，这些位按逆序存到 NULL 值列表。
* NULL 值列表必须占用整数个字节，如果有多的位，高位补零。

**记录头信息**

固定占用 5 个字节，它的 40 个二进制位分为多个部分，分别有不同的含义。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-5fa9ebde.png)

| 名字         | 大小   | 说明                                                         |
| ------------ | ------ | :----------------------------------------------------------- |
| 预留位1      | 1 bit  | 没有使用                                                     |
| 预留位2      | 1 bit  | 没有使用                                                     |
| delete_mask  | 1 bit  | 标记当前记录是否被删除                                       |
| min_rec_mask | 1 bit  | 标记 B+ 树每层最小非叶结点，即每层最小目录项记录             |
| n_owned      | 4 bit  | 记录代表的分组包含的记录数，这条记录的偏移量就是槽           |
| heap_no      | 13 bit | 记录在页面堆的序号                                           |
| record_type  | 3 bit  | 记录的类型，0 普通记录，1 目录项记录，2 最小记录，3 最大记录 |
| next_record  | 16 bit | 下一条记录的真实数据的相对位置                               |

**真实数据**

除了表示用户数据的列，InnoDB 还会为记录添加一些列，即隐藏列。比如，InnoDB 表必须有主键，如果用户没有定义主键，就选一个值不允许为 `null` 的 `unique` 列作为主键，如果没有这样的列，那就生成 db_row_id 列作为主键。

| 隐藏列      | 必需 | 大小   | 说明                            |
| ----------- | ---- | ------ | ------------------------------- |
| db_row_id   | 否   | 6 byte | 记录 ID，表内唯一标识一条记录。 |
| db_trx_id   | 是   | 6      | 事务 ID                         |
| db_roll_ptr | 是   | 7 byte | 回滚指针                        |

COMPACT 对 `char(M)` 字段的处理有些特殊。如果字符集对每个字符都固定使用 N 个字节编码，那么这个字段固定占用 M*N 个字节，空闲空间空格补齐。如果字符集是变长编码，COMPACT 就把它视为变长字段，需要记录真实数据的长度，这个字段至少占用 M 个字节，这能减少空间的再分配，降低空间碎片的产生概率。

## REDUNDANT

MySQL 5.0 使用 REDUNDANT 作为默认的行格式。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-204eab88.png)

字段长度偏移量是列的值在真实数据的结束位置，这样就能使用两个相邻的偏移量来计算列值长度。

记录头信息固定占用 6 个字节，相比于 COMPACT，它没有 record_type 属性，另外多出两个属性。

| 名字            | 大小  | 说明                              |
| --------------- | ----- | --------------------------------- |
| n_field         | 4 bit | 列的数量                          |
| 1byte_offs_flag | 1 bit | 使用 1 或 2 个字节保存 1 个偏移量 |

REDUNDANT 根据记录的真实数据总的大小来设置使用 1 或 2 个字节保存偏移量：

* 如果真实数据的总字节数小于 127，每个偏移量占用 1 字节。
* 如果总字节数大于 127，但不大于 32767，每个偏移量占用 2 字节。
* 如果总字节数超过 32767 字节，把部分数据放到溢出页。

REDUNDANT 使用偏移量的第 1 个位表示对应的列是否为 `null`，定长类型即使为 `null` 也占用固定大小，变长类型如果为 `null`，则不占用空间。

对于 `char(M)` 字段，不论什么字符集，REDUNDANT 固定使用 N*M 个字节。可以看出，REDUNDANT 组织数据的方式比较简单，因此使用的空间比 COMPACT 多得多。

## 其它行格式

DYNAMIC、COMPRESSED 和 COMPACT 非常相似，但在处理溢出列时稍有不同，它们不会在当前页保留溢出列的任何数据，即溢出列的所有内容都在溢出页，列值是溢出页的地址。

另外，COMPRESSED 还会对页面进行压缩，节省空间。

## 溢出列结构

记录存于页内，页是一种数据结构，它的大小有限，所以每个页的记录也有限。如果某个列的值非常大，超出页的限制，就需要使用溢出页，这个列称为溢出列。

COMPACT 和 REDUNDANT 会在当前页保存溢出列的部分数据，而 DYNAMIC 和 COMPRESSED 则是把溢出列的全部内容都放到溢出页。不过，它们都会在列值处使用 20 个字节记录溢出页的地址。

溢出的数据可能需要使用多张溢出页，这些页连成一个单向链表，溢出列保存的是头结点页的地址。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-b9dcdf86.png)

# InnoDB 的 index 页

## 页和 index 页

页是 InnoDB 管理存储空间的基本单位，即使读取一条记录，也会加载整个页面。当数据量较大时，还会使用更大范围的区。

页有许多种类型，这里学习用于存储索引的 index 页。由于 InnoDB 是 "数据即索引"，所以，index 页又被成为数据页。默认 index 页的大小是 16KB，它的结构如下所示。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-045e3256.png)

| 名字               | 名字           | 大小    | 说明                         |
| ------------------ | -------------- | ------- | ---------------------------- |
| File Header        | 文件头部       | 38 byte | 页的通用信息                 |
| Page Header        | 页面头部       | 56 byte | index 页专门信息             |
| Infimum + Supremum | 最小和最大记录 | 26 byte | 两条虚拟记录                 |
| User Records       | 用户记录       | 不确定  | 真正的表记录                 |
| Free Space         | 空闲空间       | 不确定  | 页中尚未使用的空间           |
| Page Directory     | 页目录         | 不确定  | 某些记录的相对位置（页目录） |
| File Trailer       | 文件尾部       | 8 byte  | 校验页是否完整               |

## 页的用户记录

表示用户数据的记录在页的 User Records 部分，页初始时没有任何记录，自然也没有 User Records 部分，后面每向页插入一条记录，就要从 Free Space 划分一些空间到 User Records 部分，如果没有空闲空间，就需要申请新的 index 页。

页存储记录时，需要使用行格式的"记录头信息"，这里以 COMPACT 为例进行学习。

**delete_mask**

当 delete_mask 为 1 时，表示这条记录被删除，由此可见，MySQL 的 delete 操作是逻辑删除，因为真正地把数据从磁盘删除，需要重新排列剩余的数据，这会严重影响 delete 的性能。

所有被删除的记录，使用记录头信息的 next_record 属性组成一条单向链表，后面插入的新记录，可能会回收使用垃圾链表的结点占用的空间。

**heap_no**

用户记录都在 User Records 部分，紧密排列，InnoDB 把这种结构称为堆。记录头信息 heap_no 属性表示记录在堆内的序号，即这是页的第几条记录，从 0 开始，按 1 迭代。

注意，用户记录的 heap_no 属性从 2 开始，因为页初始会添加两条虚拟记录：最小记录、最大记录。记录根据主键比较大小。

记录一旦设置 heap_no 成功，值就不可变，即使记录被删除，这个值也不会被赋给其它记录。

**next_record**

记录使用 next_record 属性，按照主键升序，组成一条单向链表，且以 Supremum 作为头结点，Infimum 作为尾结点。这个 next_record 属性，表示当前记录的真实数据，距离下一条记录的真实数据多少个字节，正值表示下一条记录在当前记录的后面。

**重用已删除记录的空间**

Page Header 有一个属性 PAGE_GARBAGE，记录页面可重用存储空间的总字节数，属性 PAGE_FREE 指向垃圾链表头结点。每次插入一条记录，首先判断 PAGE_FREE 指向的头结点的空间是否足以容纳新记录，如果可以就直接重用这条已删除记录，并会更新 PAGE_FREE 指向垃圾链表下一条记录。

因为新记录通常不会与已删除记录同样大，即比它小，这会产生空间碎片，这些碎片会被统计到 PAGE_GARBAGE 属性，碎片在整个页面快使用完前不会被利用。直到页面快写满，现在插入一条记录，页面无法分配一条完整记录空间，这时先看一下 PAGE_GARBAGE 空间和剩余可利用空间加起来是否可以容纳新记录，如果可以，InnoDB 将会重新组织页内记录，过程就是创建一个临时页把所有记录依次插入一遍，从而消除空间碎片，然后把临时页内容复制回原页面，最后插入新记录，完美利用空间碎片。显然，重新组织页面记录比较耗费性能。

如果碎片+剩余空闲空间都不足以容纳新记录，那就只能进行页面分裂。

## 页目录 Page Directory

页目录用于优化根据键值的查询命令，非常重要。已知所有记录按照升序组成单向链表，根据键值查找记录，最简单的方式就是遍历记录链表，性能很低，明显不靠谱。

为此，index 页把记录链表截成多个组，每组的最后一个结点是该组的最大记录。然后，把每组的最后一条记录的偏移量提取出来，逆序存放在靠近页尾的地方，这就是页目录。这些偏移量称为槽，每个槽占用 2 字节。

现在，根据键值查找记录的命令，将按以下步骤执行：

* 二分查找，不断迭代，确定目标记录所在分组的槽。
* 根据前一个槽，遍历目标槽的所有记录，直到找到目标记录。

这样，根据键值的查询的效率将大大提升，即把遍历整个链表，优化为遍历一个子链。

InnoDB 规定，Infimum 分组只有一条记录，其它分组的记录在 4~8 条之间，所以页目录至少有两个槽。新的记录会加入键值比它大，且差值最小的槽所代表的分组，如果分组的记录数达到 8，则把它一分为二，新增一个槽。

## 页头部 Page Header

占用 56 个字节，存储 index 页的状态信息。

| 状态                | 大小    | 说明                                               |
| ------------------- | ------- | -------------------------------------------------- |
| PAGE_N_DIR_SLOTS    | 2 byte  | 页中槽的数量                                       |
| PAGE_HEAP_TOP       | 2 byte  | 空闲空间 Free Space 的开始地址                     |
| PAGE_N_RECS         | 2 byte  | 页的记录数量，只是未被删除的"用户记录"             |
| PAGE_N_HEAP         | 2 byte  | 页的记录数量，包括最小、最大和删除的记录           |
| PAGE_FREE           | 2 byte  | 第一条标记删除的记录的地址，即垃圾链表头结点的地址 |
| PAGE_GARBAGE        | 2 byte  | 删除的记录总的字节数                               |
| PAGE_LAST_INSERT    | 2 byte  | 最近插入记录的位置                                 |
| PAGE_DIRECTION      | 2 byte  | 最新一条记录的插入方向                             |
| PAGE_N_DIRECTION    | 2 byte  | 相同方向的连续插入次数                             |
| PAGE_MAX_TRX_ID     | 8 byte  | 修改当前页的最大事务 ID，只在二级索引设置          |
| PAGE_INDEX_ID       | 8 byte  | 索引 ID，表示当前页属于哪个索引                    |
| PAGE_LEVEL          | 2 byte  | 页在 B+ 树的层级，最低 1 是叶结点                  |
| PAGE_BTR_SEG_LEAF   | 10 byte | B+ 树叶子段的头部信息，仅在 B+ 树的 Root 页定义    |
| PAGE_BTR_SEG_TOP 10 | 10 byte | B+ 树非叶子段的头部信息，仅在 B+ 树的 Root 页定义  |

**插入方向**：插入的记录如果比上一条插入的记录大，它的插入方向是右边，否则是左边。

## 页的通用部分

前面的部分都是 index 页特有的内容，File Header 和 File Trailer 是任何类型的页都有的通用内容。

### 文件头 File Header

占用 38 字节，保存页的各种通用信息。每个页都有一个表空间内唯一的页号，用于标识和快速定位，它占用 4 个字节，第一个页的页号是 0，所以表空间的页的数量有限。有些页支持组成链表，比如 Index 页，这些页只是逻辑连接，不需物理相邻。

| 状态                             | 大小   | 说明                                                         |
| -------------------------------- | ------ | ------------------------------------------------------------ |
| FIL_PAGE_SPACE_OR_CHKSUM         | 4 byte | 页的校验和，版本 4.0.14 以前表示表空间 ID                    |
| FIL_PAGE_OFFSET                  | 4 byte | 页号                                                         |
| FIL_PAGE_PREV                    | 4 byte | 上一个页的页号                                               |
| FIL_PAGE_NEXT                    | 4 byte | 下一个页的页号                                               |
| FIL_PAGE_TYPE                    | 2 byte | 页的类型                                                     |
| FIL_PAGE_LSN                     | 8 byte | 页最近一次修改时对应的 LSN 值                                |
| FIL_PAGE_FILE_FLUSH_LSN          | 8 byte | 只在系统表空间的第一个页定义，表示文件至少被刷新到这个 LSN 值 |
| FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID | 4 byte | 页所属的表空间                                               |

**FIL_PAGE_OFFSET**

页号用于在表空间内唯一定位一个页，每个页都有页号。

**FIL_PAGE_SPACE_OR_CHKSUM**

页的校验和。所谓校验和，就是使用算法，对字符串计算出一个较短的结果，如果两条字符串的校验和不同，那它们肯定不相等。

**FIL_PAGE_TYPE**

页的类型，索引页是 FIL_PAGE_INDEX，溢出页是 FIL_PAGE_TYPE_BLOB。

**FIL_PAGE_PREV 和 FIL_PAGE_NEXT**

如果表很大，可能需要多个页保存它的数据，FIL_PAGE_PREV 和 FIL_PAGE_NEXT 属性把这些页串联起来，组成双向链表。并非所有类型的页都有使用这两个属性，但 index 页有用。

### 文件尾 File Trailer

占用 8 个字节，用于校验页的完整性。前 4 个字节是页的校验和，与 File Header 的校验和对应，后 4 个字节是页最近一次修改时的 LSN 值，与 File Header 的 LSN 对应。File Header 在页的前面，会先被刷盘，如果没有发生意外，File Trailer 的这两个属性应该与 File Header 一致，除非发生错误，导致 File Trailer 没有被更新。

# MySQL 数据目录

像 InnoDB、MyISAM 这类存储引擎会把数据持久化，数据的存放位置是**数据目录**，这个目录的路径对应一个系统变量 "datadir"，类 UNIX 平台默认 */usr/local/var/mysql*。

```
show variables like 'datadir';
```

## 通用结构

**数据库目录**

每个数据库都对应数据目录下的一个同名子目录，每个数据库子目录都有一个 *db.opt* 文件，这个文件保存数据库的一些元数据，比如字符集、比较规则。

**表结构文件**

数据表的信息分为结构定义和用户记录，前者包含表名、字符集、比较规则这些元数据，InnoDB、MyISAM 会为每个表创建一个的同名文件，后缀 *.frm*，放在数据库子目录，这个文件以二进制格式存储表结构信息。

至于用户记录，各个存储引擎使用不同的方式进行存储。

## 数据存储

### InnoDB 表空间

InnoDB 使用表空间管理 index 页。表空间是一个抽象概念，对应文件系统上的一个或多个文件，可以把它看作数据页的集合，表的数据存放在某个表空间下的某些页。有多个类型的表空间。

**系统表空间**

默认情况，InnoDB 将在数据目录创建一个文件，名为 *ibdata1*，大小 12MB，它是系统表空间的实现。这么点大当然不够，这个文件能够进行自扩展。

通过配置参数，可以指定系统表空间对应多个文件，以及这些文件的名字、自扩展性等。以下配置，MySQL 启动之后将会创建两个 512M 大小的文件作为系统表空间，关键字 autoextend 表示 *data2* 允许自扩展。

```
[server]
innodb_data_file_path=data1:512M;data2:512M:autoextend
```

> 系统表空间还可以配置放在其它目录，不多赘述。

每个 MySQL 实例只有一份系统表空间，版本 5.5.7 至 5.6.6，InnoDB 默认把表的数据存到系统表空间。

**独立表空间**

MySQL 5.6.6 以及之后，InnoDB 会为每个表创建一个独立表空间，表的数据默认被存放到对应的独立表空间而非系统表空间。每个表的独立表空间对应一个数据库子目录下的与表同名的文件，后缀 *.ibd*。

通过配置参数 `innodb_file_per_table` 指定数据保存到系统表空间，默认值 1 表示使用独立表空间，修改参数只对新建的表起作用。

```
[server]
innodb_file_per_table=0
```

把表的数据从系统表空间转移到独立表空间。

```
alter table 表名 tablespace [=] innodb_file_per_table;
```

把表的数据从独立表空间转移到系统表空间。

```
alter table 表名 tablespace [=] innodb_system;
```

**其它表空间**

通用表空间，undo 表空间，临时表空间，等等。

### MyISAM 表文件

MySQL 会在数据库子目录下为每个 MyISAM 表创建两个同名文件，后缀 *.MYD* 存放数据，后缀 *.MYI* 存放索引。

## 系统数据库

MySQL 初始自带几个数据库，它们包含服务程序运行需要的数据，以及一些运行状态信息：

* **mysql**

  重要核心，包含用户账户和权限信息，某些存储过程和事件、运行日志、帮助信息，以及时区信息，等等。

* **information_schema**

  服务器维护的所有其它数据库的元数据，比如有哪些表、哪些列，哪些索引，这个库没有对应的子目录。

* **performance_schema**

  服务器运行过程中的一些状态信息，包括最近执行的语句，执行过程每个阶段的耗时，内存使用情况，等等。

* **sys**

  以视图的形式把 information_schema 和 performance_schema 结合起来，综合展示服务器运行状态。

# InnoDB 的表空间

## 独立表空间

独立表空间的结构更加简单，系统表空间还要额外包含一些关于整个系统的信息。

### 区和段的概念

**区的概念**

表空间可以有很多个页，为了管理大量的页，InnoDB 提出区的概念。对于 16KB 大小的页，区由 64 个连续的页组成，因此，区默认 1MB 大小。独立表空间和系统表空间，都能看作由若干个连续的区组成。

每 256 个区划分为一组，并且，表空间第一个组的前 3 个页，以及其它组的前两个页的页面类型固定。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-5476262f.png)

FSP_HDR 保存本组所有区的属性和表空间的整体属性，每个表空间只有第一个页是这种类型；IBUF_BITMAP 保存 Change Buffer 相关信息；INODE 保存 INODE Entry 数据结构；XDES 保存本组所有区的属性。

**段的概念**

扫描 B+ 树，InnoDB 首先根据条件定位到一条用户记录，然后沿着记录链表和页面链表向后遍历。如果叶结点页比较分散，遍历会产生大量随机 I/O，降低性能。所以，应该尽量让链表相邻的页同时物理相邻，这样就能在遍历时使用顺序 I/O。区的作用就是如此，它的页都物理相邻，页号连续，如果表的数据量很大，InnoDB 就会按区来为索引分配空间，甚至一次性分配多个连续的区。这可能造成浪费，因为数据往往不能完全填充整个区，但能有效减少随机 I/O。

只有叶结点才会被遍历，如果把叶结点和非叶结点混放，遍历效果将大打折扣。所以，InnoDB 使用不同的区来存储叶结点和非叶结点。存放叶结点的区是一个段，存放非叶结点的区是另一个段。每个索引都有两个段，即叶结点段和非叶结点段。

其实，段不是一开始就直接分配完整的区，这对数据量较小的索引来说非常浪费，而是先从碎片区按页来分配存储空间，当段占用 **32** 个页之后，再以区为单位分配，前面获得的碎片页保留，其中的数据也不会转移。所以，**段是零散的页和一些完整的区的集合**。

### 区和段的结构

**区的状态**

表空间的区有 4 种状态，除了 FSEG，其它状态的区都直属表空间管理。

| 状态      | 说明                                               |
| --------- | -------------------------------------------------- |
| FREE      | 空闲的区，页都没有被使用                           |
| FREE_FRAG | 还有剩余空闲空间的**碎片区**，有些页还未被分配使用 |
| FULL_FRAG | 没有剩余空闲空间的**碎片区**，所有页都已被分配使用 |
| FSEG      | 附属于某个段的区                                   |

**XDES Entry 结构**

InnoDB 使用 XDES Entry 结构管理区，每个区都对应一个 XDES Entry，结构中记录着对应的区的一些属性。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-8ab1d0f2.jpg)

| 组成部分          | 大小    | 说明                                                         |
| ----------------- | ------- | ------------------------------------------------------------ |
| Segment ID        | 8 byte  | 所属段的 ID                                                  |
| List Node         | 12 byte | 连接多个 XDES Entry 成为链表，结构如下所示                   |
| State             | 4 byte  | 区的状态                                                     |
| Page State Bitmap | 16 byte | 每两个位对应区的一个页，第一个位表示页是否空闲，第二个位没用 |

List Node 有 4 个属性，分别表示前、后 XDES Entry 的页号和页内偏移量。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-b54ef39c.jpg)

**XDES Entry 链表**

InnoDB 怎么快速找到指定状态的区？为此，表空间把**直属**的区对应的 XDES Entry 组成 3 个链表：

* FREE 链表：其中的区都是 FREE 状态；
* FREE_FRAG 链表：其中的区都是 FREE_FRAG 状态；
* FULL_FULL 链表：其中的区都是 FULL_FULL 状态。

现在，表空间需要时可以直接从 FREE_FRAG 链表取出一个结点来申请碎片页，以及从 FREE 链表申请区。

每个段也会根据其包含的区的使用情况，把它们对应的 XDES Entry 组成 3 个链表：

* FREE 链表：其中的区的所有页面都未被使用；
* NOT_FULL 链表：其中的区的部分页面已被使用；
* FULL 链表：其中的区的所有页面都被使用。

**List Base Node 链表基结点**

InnoDB 使用 List Base Node 结构管理 XDES Entry 链表，List Length 表示链表结点数量。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-ed530fe9.jpg)

**INODE Entry 结构**

InnoDB 使用 INODE Entry 结构管理段，每个段对应一个 INODE Entry，结构中记录着对应的段的一些属性。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-ebbe7472.jpg)

NOT_FULL_N_USED 表示已经使用了多少个 NOT_FULL 链表的页，再次分配空闲页时就能直接定位而不用从链表头挨个遍历；Magic Number 标记 INODE Entry 是否初始化；总共 32 个 Fragment Array Entry 结构，用于保存零散页的页号；另外 3 个 List Base Node，这是段的 3 个 XDES Enty 链表的基结点。

### 特殊类型页面

现在已经了解表空间、区、段、XDES Entry、INODE Entry、各种 XDES Enty 链表的概念，那么这些东西到底存放在哪里呢？这就需要深入了解每组开头的几种特殊类型页面的结构。

**FSP_HDR 类型**

以下是 FSP_HDR 页面的结构图，可以发现其保存着本组所有区的 XDES Entry 结构，Empty Space 部分用于填充页面空白，没有意义。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-d9376168.jpg)

展开 File Space Header 部分，以下是它的结构图，其保存着表空间的 3 个 XDES Enty 链表的基结点，另外还有两个基结点：SEG_INODES_FULL 和 SEG_INODES_FREE，它们是 INODE 页面组成的链表的基结点。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-e88bf5bd.jpg)

**XDES 类型**

对于 XDES 页面，没什么好说，相比 FSP_HDR 页面，它仅保存着本组所有区的 XDES Entry 结构。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-c08c4818.jpg)

**INODE 类型**

INODE 页面用于保存段的相关属性，其中主要是 INODE Entry 结构，每个 INODE Entry 对应一个段，内容包括零散页的地址以及段的 3 个 XDES Enty 链表的基结点。

如果表空间有很多个段，可能需要多个 INODE 页，这些页会根据使用情况组成两个链表：

* SEG_INODES_FULL 链表：其中的 INODE 页都没有空闲空间来存储额外的 INODE Entry 结构。
* SEG_INODES_FREE 链表：其中的 INODE 页都仍有空闲空间。

这两个链表的基结点保存在 FSP_HDR 页的 File Space Header 部分末尾。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-4640f926.jpg)

**IBUF_BITMAP 类型**

暂不学习，Change Buffer 相关内容在后面。

### Segment Header 结构

对于索引，Root 页的 Page Header 部分会保存两个属性：PAGE_BTR_SEG_LEAF、PAGE_BTR_SEG_TOP，它们是这个索引对应的叶子结点段和非叶子结点段的头部信息，对应两个 Segment Header 结构。这样，我们就能知道这个索引属于哪个段，需要时直接访问对应的 INODE Entry 结构。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-0e2f0e8b.jpg)

## 系统表空间

每个 MySQL 实例只有一个系统表空间，以下是系统表空间的整体结构，可以发现其与独立表空间相似，只是额外增加了一些有关整个系统信息的页面。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-97ea9524.jpg)

页号为 3~7 的页面都是系统表空间独有，以下是这些页面的说明。

| 页号 | 页面类型 | 说明                   |
| ---- | -------- | ---------------------- |
| 3    | SYS      | Insert Buffer 头部信息 |
| 4    | INDEX    | Insert Buffer 根页面   |
| 5    | TRX_SYS  | 事务系统相关信息       |
| 6    | SYS      | 第一个回滚段的页面     |
| 7    | SYS      | 数据字典头部信息       |

**InnoDB Data Dictionary 数据字典**

除了用户数据，MySQL 还需保存一些额外信息，比如有哪些表？这些表有哪些列、索引和外键？这类信息其实就是表的元数据，InnoDB 定义了一系列内部系统表来记录这些元数据，它们也以 B+ 树形式存放，这些系统表也被称为**数据字典**，以下是它们的基本说明。

| 表名             | 说明                     |
| ---------------- | ------------------------ |
| SYS_TABLES       | 所有表的信息             |
| SYS_COLUMNS      | 所有列的信息             |
| SYS_INDEXES      | 所有索引的信息           |
| SYS_FIELDS       | 所有索引对应的列的信息   |
| SYS_FOREIGN      | 所有外键的信息           |
| SYS_FOREIGN_COLS | 所有外键对应的列的信息   |
| SYS_TABLESPACES  | 所有表空间的信息         |
| SYS_DATAFILES    | 所有表空间对应文件的信息 |
| SYS_VIRTUAL      | 所有虚拟生成列的信息     |

SYS_TABLES 、SYS_COLUMNS 、SYS_INDEXES 、SYS_FIELDS 这 4 个表称为基本系统表，最为重要，通过它们可以获得任何其它系统表和用户表的元数据。怎么找到基本系统表？这没办法了，只能硬编码，页号为 7 的页面保存着这 4 个表的聚簇索引和二级索引对应的 B+ 树的根页面。

以下是页号为 7 的页的结构图，可以发现其管理着下一个隐藏列、表、索引、表空间的 ID 编号。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-5036dad2.jpg)

用户不能直接访问 InnoDB 内部系统表，不过，系统数据库 information_schema 提供了一些以 innodb_sys 开头的表，InnoDB 会在启动时读取系统表然后把数据填充到这些表中，当然，两边的表的结构并不完全一样。

# B+ 树索引的原理

索引是一种数据结构，设计的目的是快速检索记录。

## 聚簇索引

已经知道，在 InnoDB，表的记录存放在一个或多个 index 页，这些页组成双向链表，记录在页内按主键升序组成单向链表。每个 index 页还会生成页目录，用于二分查找，快速检索记录。

**为什么要设计索引**

如果表的记录都在一个页，根据主键的查询可以使用页目录快速检索。但是，如果查询条件是其它的列，并且这个列没有建立索引，那就只能沿着链表挨个遍历所有记录，即全表扫描。

如果表的记录分散在多个页，如何确定目标记录在哪个页呢？目前来看，只能沿着链表检查所有页面，并且，如果查询条件不是主键，还要遍历页内的记录链表。

**目录项快速定位页**

现在只考虑条件是主键的查询。如何快速定位目标记录所在的页呢？参考页目录的设计，把所有数据页按照主键升序排列，组成双向链表，即后一个页的主键都比前一个页大，然后提取每个页的最大键值。这样，就能通过比较查询条件和各个页的最大键值，快速目标记录所在的页。

如何管理每个页的最大键值，关联这些值和对应的页呢？InnoDB 把这些信息存到 index 页，不过，这时的记录类型是目录项记录。对于主键索引，目录项记录有两个字段：最大键值和页号。现在，就能像普通的数据页那样检索目录项，查找页号，定位目标页。

**分裂分层和 B+ 树**

页的空闲空间如果不足以存放新的记录，这时会生成一个新页，用于保存多余的记录，这叫"页分裂"。新的记录不一定在新的页，因为要保证页间的主键顺序，所以新记录可能插到前面的页，把旧记录移到新页。无论数据页或目录页，都能进行页分裂。

如果数据页很多，目录项自然也会很多，可能会有多个目录页。这时，检索最开始又该如何确定目标记录在哪个目录页呢？很简单，照搬前面的方案，构建目录页的目录页，同级的目录页按照主键升序组成双向链表。这样不断地构建范围更大的目录页，直到顶层只有一个页，这个页叫做 Root 页。

这种数据结构就是 B+ 树，底层的数据页称作叶结点，中间的目录页称作内结点。MySQL 把最下面的叶结点那层看作第 0 层，层级向上依次递增。对于 InnoDB，所有索引都是 B+ 树结构。使用 B+ 树索引查找记录，都是从顶层的 Root 页开始。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-73064f39.jpg)

**聚簇索引就是数据**

MySQL 把叶结点保存着完整用户记录，根据**主键**排序的 B+ 树，称为聚簇索引。"根据主键排序"有两个意思：

* 页内记录按主键升序组成单链表
* 同层页间按主键升序组成双链表

InnoDB 表本身就以 B+ 树的结构存储，所以，InnoDB 表是一个聚簇索引，这就是**索引即数据**。

每当为一个表创建 B+ 树索引，会先为它创建一个 Root 页，初始 Root 页为空。最开始，插入的用户记录会直接存到 Root 页，直到 Root 页的空闲空间不足，再生成一个新页，把 Root 页的记录复制到新页，新页又进行页分裂并存入新记录，同时，Root 页更新为目录页。

## 其它索引

**二级索引**

聚簇索引只能用于根据主键的搜索，如果条件是其它的列怎么办？InnoDB 允许为普通列创建 B+ 树索引，这种索引称做二级索引或辅助索引，页内和页间根据索引列排序，叶结点只保存索引列和主键，而非完整记录。

如果想通过二级索引查找完整的记录，还要根据叶结点的主键值查找聚簇索引，这叫"回表"。因为普通列的值可能重复，所以二级索引的查找，不是找到一个就结束，而是先找到第一个满足的叶结点，然后沿着底层的链表向后遍历和回表，直到遇见条件不满足的记录，最后返回所有满足条件的记录。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-c4520890.jpg)

**联合索引**

联合索引也是二级索引，只不过它有多个索引列。假设 C1、C2 是索引列，B+ 树先根据 C1 排序，如果这个列的值相等，再根据 C2 排序。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-8495c305.jpg)

## 注意事项

**内结点的目录项的唯一性**

对于聚簇索引，目录项只包含主键和页号，但这对于二级索引不太严谨，因为二级索引可能存在多个叶结点的最大值都相同，这会导致目录页有多个相同的目录项。所以，二级索引的目录项增加一个列：主键，这就可以保证目录项的唯一性。并且，二级索引的目录项在索引列相等时，根据主键排序。

**B+ 树百万级别的储存性能**

假设每个数据页保存 100 条记录，每个目录页保存 1000 条记录。这样，单层的 B+ 树可以保存 100 条记录，双层的 B+ 树可以保存 100,000 条记录，三层的 B+ 树可以保存 100,000,000 条记录，这已经是百万级别，四层甚至达到亿万级别。

对于大部分数据表，三层的 B+ 树足以存放所有数据，但这也是百万级别。即使是这么大的数据量，每次根据索引列的检索，通常只会查找 3 个页面，即 2 个目录页和 1 个数据页，并且在页内，还有页目录的支持。

**每个页面最少有两条记录**

B+ 树之所以储存这么多数据，查询速度还那么快，因为 B+ 树本质是一个多层目录，每经过一个目录，就能筛选掉许多子目录。如果一个结点只有一条记录，目录的层数会非常多，每次检索需要查找大量的页。

所以，MySQL 规定 index 页至少有两条记录。根据这个规定，还可以计算可变长列最多能存放多少字节。

## MyISAM 索引

MyISAM 存储引擎也支持索引，同样把索引组织为树。不同的是，MyISAM 把数据和索引分开管理，表的所有记录都放在一个数据文件。MyISAM 表会自动为主键创建索引，索引信息放在一个索引文件，索引的叶结点保存的是键值+记录指针，而非完整的记录。查找先根据索引获取指针，然后通过指针从数据文件拿到目标记录。

所以，MyISAM 建立的所有索引都是二级索引。如果需要，可以对其它列建立索引或联合索引，原理类似。

# B+ 树索引的应用

## 索引的代价

**空间上的代价**

对于 InnoDB，建立一个索引，就是创建一颗 B+ 树，每个结点都是 index 页，每个页默认占用 16KB 空间。

**时间上的代价**

每次修改表的数据，为了维护 B+ 树结构，需要进行相应的修改，比如页分裂、页回收。如果表的索引太多，那么每个简单的修改，都有可能引发大量的 B+ 树更新，这会带来很大的性能消耗。

另外，执行查询语句之前要生成一个执行计划，这个计划会计算使用各个索引的成本，最后选择成本最低的索引执行查询。如果表的索引太多，这会增加成本分析的耗时。

## 索引的应用

### 索引用于查询

如果不用索引，查询将选择全表扫描的执行方案，遍历所有记录，即从最左边开始，沿着底层链表，扫描聚簇索引的用户记录。

**扫描区间和边界条件**

查询使用索引，首先找到第一个**符合条件**的记录，接着向后遍历，直到遇见不符合条件的记录。"符合条件"指符合边界条件。遍历的范围叫做扫描区间，这把原本的全表扫描优化为扫描某个区间，形成扫描区间所用的查询条件叫做边界条件。

扫描区间不是最终结果，而是缩小的检索范围，遍历到的每条记录，还要使用非边界条件进行二次判断，对于二级索引，可能还要回表获得其它字段才能进行二次判断。

有的扫描区间只有一个值，称为单点扫描区间，包含多个值的扫描区间叫做范围扫描区间。对于全表扫描，可以看作聚簇索引的 (-∞,+∞) 扫描区间。

**扫描区间的计算方式**

查询语句可能有多个索引可用，计算某个索引的扫描区间时，可以把不相关的条件与 True 等同。每个小条件都会形成一个扫描区间，使用 AND 连接的条件，取扫描区间的交集，使用 OR 连接的条件，取扫描区间的并集。最后的结果，就是使用这个索引时的扫描区间。

联合索引，有些条件虽然涉及索引列，但不能作为边界条件。因为，只有前一个索引列的值固定，记录才根据当前列排序。如果前一个索引列不固定，那后一个索引列的条件不可用。

### 索引用于排序

**文件排序**

使用 ORDER BY 子句排序结果集，需要把数据加载到内存，使用排序算法进行排序，当结果集太大时，还要借助磁盘存放中间结果，最后返回客户端。MySQL 把这种排序方式称为文件排序。

**索引排序**

如果 ORDER BY 使用索引列，可能会省去文件排序的步骤。因为索引本身有序，如果 ORDER BY 子句的排序规则和索引一致，那么遍历索引就是 ORDER BY 期望的结果。降序 DESC 也能使用索引，通过"查找某条记录的上一条记录"进行实现，这比"查找某条记录"稍微复杂。

如果 ORDER BY 想要使用联合索引，排序列的顺序应该与索引列的左侧连续顺序一致，即最左原则。

**无法使用索引的情况**

用于排序的列不属于同一个索引。

用于排序的列不符合联合索引的最左原则。

排序列不是以单独列名出现，可能被修饰，比如使用函数。

混用 ASC 和 DESC，这种情况即使能用索引，消耗也会很大，执行计划基本不会选择这个方案。

形成扫描区间的索引列与排序列不同，这时索引的扫描顺序与排序列无关。

### 索引用于分组

类似于索引排序。通常，分组会使用临时表存放中间结果。如果用于分组的列是索引列，那么同组的记录在索引的底层连续，直接遍历索引可以快速得到分组结果，然后进行其它的统计操作。

## 创建和使用

**索引目标**

应该只为 WHERE 子句中的列、连接子句中的列，或者 ORDER BY、GROUP BY 中的列创建索引。

**索引下推**

对于二级索引，如果非边界条件的列被用户记录包含，那么不用回表，直接原地进行二次判断。

**覆盖索引**

对于二级索引，如果查询的列被用户记录包含，那么不用回表，直接返回结果。

**最左原则**

不多赘述，考虑联合索引的排序规则，就知道只有最左原则才能利用联合索引。

**前缀索引**

对于较长的字符串列，建立完整的索引比较耗费空间，可以只对部分前缀建立索引，索引根据前缀排序。

```
alter table 表名 add index 索引名(列名(前缀长度));
```

# InnoDB 页的缓冲

## 缓冲池 Buffer Pool

页是 InnoDB 管理存储空间的基本单位，即使客户端请求只要一条记录，InooDB 也会加载整页。并且，数据读写完毕之后不会立即释放页的内存，而是缓存起来以便下次使用，减少磁盘 I/O。

为了缓存磁盘中的页，InnoDB 会在启动时向操作系统申请一片连续的内存，称为 Buffer Pool，InnoDB 加载的页都会放在这里。Buffer Pool 默认大小 128M，最小 5M。以下配置指定 Buffer Pool 大小为 256M，单位 Byte。

```
[server]
innodb_buffer_pool_size = 268435456
```

## 缓冲页 Cache Page

Buffer Pool 这块连续的内存空间被 InnoDB 划分成若干个页，页的大小与 InnoDB 表空间的页面大小一致，默认 都是 16KB，这些页称为缓冲页，用于存放 InnoDB 读取的磁盘页的缓存。

为了管理缓冲页，InnoDB 会为每个缓冲页创建一些控制信息，其中包括对应页的表空间编号、页号、页在缓冲区内的地址、链表结点信息、锁的信息，以及 LSN 信息。每个缓冲页的控制信息都占用相同大小的空间，单个缓冲页对应的控制信息占用的一块内存称为控制块。

缓冲页和控制块都放在 Buffer Pool 之中，缓冲页放在 Buffer Pool 前面，控制块放在 Buffer Pool 后面。可能会有一些内存碎片，因为剩余空间可能不足以分配一对缓冲页和控制块。

DEBUG 模式之下，每个控制块约占缓冲页大小 5%，非 DEBUG 模式更小，配置参数指定的缓冲区大小并不包括控制块，所以 Buffer Pool 真正申请的内存会比 innodb_buffer_pool_size 值大 5% 左右。

## 各种控制块链表

### Free 链表

为了快速知道哪些缓冲页空闲可用，InnoDB 会在 Buffer Pool 初始化之后创建一个链表，它的结点是空闲的缓冲页对应的控制块，称作 Free 链表。控制块初始时都在 Free 链表中，InnoDB 每次加载磁盘页，都要从 Free 链表取出一个控制块，对其填充磁盘页的信息，表示这个缓冲页已被使用。

InnoDB 会为 Free 链表定义一个基结点，其中记录头结点、尾结点、链表长度等信息。注意，基结点占用的内存空间并不包含在 Buffer Pool 中，它是一块单独的内存。其它控制块链表也有类似的基结点。

### Flush 链表

修改缓冲页的数据之后，它的内容就和磁盘页不一致，这种缓冲页称为**脏页**。为了保证数据一致，最简单的做法是每发生一次修改就立即同步到磁盘，但这会产生大量 I/O 影响性能。所以，脏页不会立即刷盘，而是在未来某个时间点统一进行磁盘同步。

为了快速知道哪些缓冲页是脏页，InnoDB 会创建一个链表，称作 Flush 链表，凡是修改过的缓冲页对应的控制块都会作为一个结点插到这个链表的头部，如果已被插入则什么都不做。

如果一个缓冲页空闲，那它肯定不在 Flush 链表，如果一个缓冲页是脏页，那它肯定不在 Free 链表，所以，控制块不可能既是 Free 结点，又是 Flush 结点。

### LRU 链表

**初步认识**

Buffer Pool 毕竟大小有限，如果 Free 没有剩余结点，那就需要释放旧的磁盘页来腾出缓冲页。Buffer Pool 使用最近最少使用算法管理使用中的缓冲页：Buffer Pool 创建一个 LRU 链表，以后每次加载磁盘页都会将其插入这个链表的头部，如果页已被加载，那就把它移到链表头部。这样，链表靠后的结点就是最近最少使用的页，缓冲页不足时优先释放这些页。

**链表分区**

简单 LRU 链表存在一些问题：预读和全表扫描都会加载大量磁盘页，而这些页大多都不会再次使用，甚至一次都没有使用，这会使缓冲页命中率急剧下降，浪费内存，增加磁盘 I/O。

> **预读**：如果 InnoDB 认为当前请求的执行可能会用到某些页面，它就预先**异步**加载这些页面，以此提高请求执行速度。预读分为线性预读和随机预读，后者默认关闭。

为此，Buffer Pool 对 LRU 链表进行分区，有一部分存放使用频率较高的页，称为 young 区域，另一部分存放使用频率较低的页，称为 old 区域。LRU 链表根据特定比例分区，系统变量 innodb_old_blocks_pct 表示 old 区域占比，以下使用配置参数指定它的值，另外还支持运行时修改。某些结点的所属分区可能随着程序运行发生变化。

```
[server]
innodb_old_blocks_pct = 40
```

现在，加载一个磁盘页到 Buffer Pool，首先把它放在 old 区域头部，随后对这个页的访问会使它移至 young 区域头部，如果 old 区域的缓冲页长时间未被访问，就会慢慢被移到尾部，这些页会在缓冲页不足时被优先释放。

另外还有一个机制：处于 old 区域的页第一次被访问时，控制块会记下这个时间，如果后续访问的时间与首次访问没有超出某个时间间隔，那么这个页将不会移到 young 区域头部。系统变量 innodb_old_blocks_time 表示这个时间间隔，默认 1000，单位 ms，可以使用配置参数指定，它也支持运行时动态修改。这个机制可以防止全表扫描把 young 区域的记录全部挤走，因为 InnoDB 认为读一条记录就算一次页面访问。

当然，Buffer Pool 还有很多优化机制，它们最终的目的都是：**提高缓冲页的命中率，减少磁盘 I/O**。

### 缓冲页哈希

为了快速知道某个磁盘页是否已经被加载，InnoDB 创建一个哈希表，键是 "表空间号 + 页号"，值是缓冲页。现在若要访问某个页，nnoDB 首先根据 " 表空间号 + 页号 " 查询哈希表，没有命中的话，再从 Free 链表取出一个缓冲页来缓存磁盘页。

## 刷新脏页到磁盘

InnoDB 有一个专门的后台线程，负责每隔一段时间把脏页刷新到磁盘，刷盘的方式有两种：

* 定时扫描 LRU 链表 old 区域尾部，扫描的页面数量可以通过系统变量 innodb_lru_scan_depth 查看，只要发现脏页就会将其刷盘，这种方式称为 BUF_FLUSH_LRU；

* 定时刷新一部分 Flush 链表页面，刷新速率取决于系统当时是否繁忙，这种方式称为 BUF_FLUSH_LRU。

某些时候，后台线程刷新脏页的进程较慢，导致没有足够的空闲缓冲页，这时 InnoDB 会扫描 LRU 链表尾部尝试直接释放未修改过的缓冲页，如果没有，则不得不把 LUR 链表尾部的脏页同步刷新到磁盘，这种对单个页面进行刷盘的方式称为 BUF_FLUSH_SINGLE_PAGE。注意，这个过程是同步进行，所以会耽误请求的执行。

## 其它的配置参数

**innodb_buffer_pool_instances**

对于 InnoDB，每个请求处理线程在访问 Buffer Pool 中的各种链表时都会加锁，所以当 Buffer Pool 比较大且并发量特别高时，只有一个 Buffer Pool 可能会影响请求的处理速度。为此，当 Buffer Pool 特别大时，应该把它拆分成多个小 Buffer Pool，每个都是一个实例，它们相互隔离，独自管理，这能提高 InnoDB 并发处理能力。

以下使用配置参数 innodb_buffer_pool_instances 指定 Buffer Pool 实例数量，默认 1。

```
[server]
innodb_buffer_pool_instances = 2
```

每个 Buffer Pool 实例占用 *innodb_buffer_pool_size/innodb_buffer_pool_instances* 大小的内存空间。缓冲池实例不是越多越好，它的管理也需要开销，当 innodb_buffer_pool_size 小于 1G 时，InnoDB 只会创建 1 个实例。

**innodb_buffer_pool_chunk_size**

MySQL 5.7.5 以前，Buffer Pool 还不能动态调整大小，那时 Buffer Pool 是一块真正完整的连续内存，调整大小要重新申请一块连续内存，然后进行数据复制，这非常耗时，所以干脆不支持。

而到 5.7.5 以及之后，Buffer Pool 进行了一些调整，它不再是一块完整连续内存，而是由许多相同大小的内存块组成，这种内存块叫做 Chunk，每个 Chunk 都是一小块连续内存。这样，Buffer Pool 就可以在运行期间调整内存大小，它以 Chunk 为单位增/减内存空间，而不需重新向系统申请一块大的内存。Chunk 的大小可以通过配置参数 innodb_buffer_pool_chunk_size 指定，默认 134217728，单位 Byte，即 128M，这个值不能运行时修改。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-6aaae7ac.jpg)

# 事务简介和应用



# 重做日志 Redo

## 初步认识

页面的修改首先只会影响 Buffer Pool 中的缓冲页，如果这时服务崩溃并且缓冲页还未刷盘，那么事务所做的修改将会丢失，为了保证事务的持久性，简单的办法是每次修改页面之后就立即刷盘，很明显这会造成大量刷盘且大多还都是随机 I/O，严重影响数据库性能。

为此，InnoDB 提供 Redo 日志用于记录页面的修改，每一个页面修改都对应一条 Redo 日志记录，相较而言日志只占用非常小空间，所以它的刷盘代价非常低，并且日志是顺序写入，那么速度就更快了。MySQL 服务启动时会读取 Redo 日志文件，然后根据日志记录恢复那些尚未持久化的修改。

## 日志格式

**通用结构**

Redo 日志其实只是记录一下事务对数据库做了哪些修改，日志有许多类型以适应不同的修改场景，绝大部分日志都有以下通用结构，其中 type 表示日志类型，space ID 表空间 ID，page number 页号，data 具体修改内容。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-c49f1ab3.jpg)

**简单 Redo 日志**

对于简单的页面修改，比如为某条记录的某个字段赋新的值，Redo 日志只需记录一下在这个页面指定偏移量处有多少字节内容被修改，以及具体修改内容，这种日志称为物理日志。InnoDB 根据修改内容的多少划分处多种物理日志类型：

* MLOG_1BYTE：表示在页面某个偏移量处写入 1 个字节修改内容；
* MLOG_2BYTE：表示在页面某个偏移量处写入 2 个字节修改内容；
* ...
* MLOG_WRITE_STRING：表示在页面某个偏移量处写入多个字节修改内容。

简单理解，InnoDB 可以直接根据物理日志 data 内容来恢复数据，没有任何多余操作。

**复杂 Redo 日志**

然而，页面修改往往比较复杂，通常牵一发而动多处，比如插入一条记录，可能要修改多个索引 B+ 树，若叶结点要进行页分裂，那么还需向内结点添加目录项记录，甚至进行内结点的页分裂，另外还需修改各种数据库内部统计信息，比如槽位、页面空间使用量、表空间管理信息等等。

怎么记录这种复杂修改呢？对每一处修改都使用一条 Redo 日志？很明显这会产生大量日志，严重浪费空间；或者使用日志 data 部分囊括一个页所有修改内容？那 data 部分将会巨大无比，同样非常浪费空间。

为此，InnoDB 设计了一些日志类型，除了修改内容，这些日志还会记录一些维护数据库正确性必须的属性，比如前一条记录的位置（用于更新页内单向链表），这类日志称为逻辑日志。服务启动时，InnoDB 将会通过调用函数并将逻辑日志包含的属性作为参数来恢复数据。

## Mini-Transaction

**按组写入日志**

语句的执行过程可能会修改多个页面，对应生成多条 Redo 日志，这些日志会被 InnoDB 按照规则划分成多个不可分割的组。所谓"不可分割"，是指同组的日志要么全部恢复，要么一条都不使用。这么做的原因很明显，既然语句产生的效果由多条日志记录，那么数据库恢复时当然要把它们一起执行，否则会恢复成错误状态。

怎么记录分组呢？已知 Redo 日志按序存储，InnoDB 会在每组结尾添加一个 LOG_MULTI_REC_END 日志，这种类型日志只有一个 type 字段，它的作用只是标记前面那些 Redo 日志属于同一个组。数据库只有解析到这个类型日志才会进行恢复，否则直接放弃前面所有日志。

很多原子性操作只有一条日志，如果这时还用 LOG_MULTI_REC_END 标记，实在有点浪费空间。日志 type 字段拥有 1 byte 空间，但 7 bit 足以表示所有类型，所以 InnoDB 就用 type 第一个 bit 表示这条记录独自一个分组

**最小事务日志（Mini-Transaction）**

MySQL 把对底层页面进行一次原子访问的过程称为一个 Mini-Transaction（MTR），根据前文可知一个 MTR 应该包含一组 Redo 日志。

事务可以包含若干条语句，每一条语句可以包含若干个 MTR，每一个 MTR 可以包含若干条 Redo 日志。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-b4e04c0c.jpg)

## 日志缓冲

**认识 Block**

Redo 日志记录同样以页为管理单位，它用的这种页通常称为 block，大小 512 字节，结构如下所示。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-4b19102a.jpg)

可见 block 就是一个简单的页面，body 部分存放 Redo 日志记录，header 和 trailer 存放管理信息，前者属性如下表所示，后者只有一个 LOG_BLOCK_CHECKSUM 属性，用于校验页面完整性。

| 属性                      | 大小   | 说明                                    |
| ------------------------- | ------ | --------------------------------------- |
| LOG_BLOCK_HDR_NO          | 4 byte | block 编号                              |
| LOG_BLOCK_HDR_DATA_LEN    | 2 byte | 已经使用了多少个字节，初始 12，写满 512 |
| LOG_BLOCK_FIRST_REC_GROUP | 2 byte | block 中第一个 MTR 的偏移量             |
| LOG_BLOCK_CHECKPOINT_NO   | 4 byte | checkpoint 序号                         |

**日志缓冲池**

自然，Redo 日志也有缓冲页机制，InnoDB 会向系统申请一大片连续内存，称为 redo log buffer，这个空间会被划分成若干个 block 页。可以通过配置参数 innodb_log_buffer_size 指定 log buffer 大小，默认 16 MB。

**写入缓冲池**

向 redo log buffer 写日志是顺序进行，前面 block 会先被写满，InnoDB 提供一个全局变量 buf_free，指示后续日志应该从缓冲区哪个位置开始写。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-1ff38a11.jpg)

MTR 可能产生多条日志，这些日志是一个不可分割的组，所以并不是每产生一条日志就把它写到缓冲区中，而是先把 MTR 运行过程中产生的日志存到一个地方，等到 MTR 结束时再把这组日志复制到 log buffer。因为不同事务可以交替执行，而 Redo 日志按组写入，所以不同事务的 MTR 可能会交替写入缓冲区。

## 日志文件

**日志刷盘时机**

Redo 日志缓冲池毕竟容量有限，因此 redo log buffer 会在一些情况下自动刷盘，比如：

* 空间不足：InnoDB 认为如果 Redo 日志占用缓冲池一半左右空间，那就需要刷盘；
* 事务提交：为了保证事务持久性，这样 Buffer Pool 就不必立即刷盘；
* 后台线程：InnoDB 有一个后台线程，大约每秒都会对 redo log buffer 刷盘；
* 停止服务：正常关闭数据库；
* 做 checkpoint 时。

**日志刷盘选项**

前面提到 Redo 缓冲区会在事务提交时自动刷盘，这条策略有点激进会严重影响性能，为此 InnoDB 提供一个系统变量 innodb_flush_log_at_trx_commit，用于调整刷盘策略，它有 3 个可选值：

* 0：事务提交时不自动刷盘，而是交给后台线程完成，无法保证事务持久性，性能最优；
* 1：默认，事务提交时立即刷盘，可以保证事务持久性，严重影响性能；
* 2：事务提交时把日志写到操作系统缓冲区，系统宕机时无法保证事务持久性，性能介中。

**日志文件组**

数据目录下默认有两个文件：ib_logfile0 和 ib_logfile1，Redo 缓冲区的日志默认会刷新到这两个文件之中，以下是一些相关配置参数：

* innodb_log_group_home_dir：指定 Redo 日志文件所在目录，默认数据目录；
* innodb_log_file_size：指定每个 Redo 日志文件大小，默认 48 MB；
* innodb_log_files_in_group：指定 Redo 日志文件数量，默认 2，最大值 100。

可以发现，Redo 日志文件可有多个，而且大小都一致。Redo 日志按序循环存储，即先写 ib_logfile0，如果这个文件写满，就接着向 ib_logfile1 写，同样，如果 ib_logfile1 写满就接着向 ib_logfile2 写，如果写满最后一个文件该怎么办呢？那就回到第一个文件 ib_logfile0 覆盖写入，旧日志为什么可以被覆盖呢？这是 checkpoin 内容。

**日志文件格式**

Redo 日志文件自然是与 reo log buffer 结构一致，即由 block 组成，刷盘其实就是把 Redo 缓冲区的 block 缓冲复制到日志文件。

每个 Redo 日志文件都可看作由两个部分组成：前 4 个 block（2048 字节）存储管理信息，其后所有空间都用于储存 redo log buffer 中的 block 镜像。普通 block 前面已经讲过，这里分析一下前 4 个 block：log file header、checkpoint1、尚未使用、checkpoint2。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-2dcdcb99.jpg)

以下列举 log file header 保存的信息，都是一些 Redo 日志文件的整体属性。

| 属性                 | 大小（字节） | 说明                                       |
| -------------------- | ------------ | ------------------------------------------ |
| LOG_HEADER_FORMAT    | 4            | Redo 日志版本                              |
| LOG_HEADER_PAD1      | 4            | 填充空白，没有意义                         |
| LOG_HEADER_START_LSN | 8            | 该 Redo 日志文件的开始 LSN 值              |
| LOG_HEADER_CREATOR   | 32           | 该 Redo 日志文件由谁创建，默认数据库版本号 |
| LOG_BLOCK_CHECKSUM   | 4            | 页的正确性校验                             |

以下列举 checkpoint1 保存的信息，都是一些 checkpoint 相关的属性，checkpoint2 与 checkpoint1 完全一样。

| 属性                        | 大小（字节） | 说明                                                        |
| --------------------------- | ------------ | ----------------------------------------------------------- |
| LOG_CHECKPOINT_NO           | 8            | 服务器做 checkpoint 的编号                                  |
| LOG_CHECKPOINT_LSN          | 8            | 服务器在结束 checkpoint 时的 LSN 值，系统恢复时将从该值开始 |
| LOG_CHECKPOINT_OFFSET       | 8            | 上一个属性的 LSN 值在 Redo 日志文件组的偏移量               |
| LOG_CHECKPOINT_LOG_BUF_SIZE | 8            | 服务器做 checkpoint 时的 redo log buffer 的大小             |
| LOG_BLOCK_CHECKSUM          | 4            | 页的正确性校验                                              |

## Log Sequeue Number

**Log Sequeue Number**

MySQL 运行之后就不断修改页面，意味着会不断生成 Redo 日志，Redo 日志量只会增加。InnoDB 提供一个全局变量记录已经写入缓冲区的 Redo 日志量，称为 Log Sequeue Number（LSN），初始值 8704。

InnoDB 是以 MTR 生成的一组日志为单位向 log buffer 写入日志，而且具体写在 block body，LSN 计算值时会把中间跨越的 block header 和 block trailer 两个部分加上。这样来看，LSN 更像是指向 log buffer 空闲空间开始位置的指针，只是初始值不为 0 而已。日志组写入完成时对应一个 LSN 值表示结束位置，值越小则日志越早产生。

**LSN 对应日志文件偏移量**

因为 redo log buffer 与 Redo 日志文件结构几乎相同，所以，可以很轻易地计算某一个 LSN 值在 Redo 日志文件组的偏移量，LSN 初始 8704 对应 Redo 日志文件组偏移量 2048，因为文件前 4 个 block 影响，当然，后面每个日志文件都有 4 个 block 干扰，不多详述。

**Flush 链表中的 LSN 属性**

每个 MTR 结束时除了要把日志组写到 log buffer，另外还得把修改的页面插到 Flush 链表，缓冲页控制块有两个属性用于记录 LSN 值，它们分别是：

* oldest_modification：缓冲页被加载之后，第一次修改该页的 MTR 的 LSN 值（结束 LSN 值）；
* newest_modification：最近一次修改该缓冲页的 MTR 的 LSN 值

现在，复述一次 Flush 更新过程：首先加载磁盘页为缓冲页，填充控制块信息；有一个 MTR 修改页面，结束时更新控制块的两个 LSN 属性，然后将其插到 Flush 链表头部；过一段时间，又有一个 MTR 修改该页，结束时更新控制块 newest_modification 属性，但不修改其在 Flush 链表的位置和 oldest_modification 属性，所以 Flush 链表是按照首次修改时间排序，越靠后越先发生修改。

## checkpoint

为了节省空间，InnoDB 选择循环使用 Redo 日志文件组，这么做可能会使旧日志被新日志覆盖。Redo 日志只是为了系统崩溃后恢复脏页使用，若脏页已被刷盘，那么对应的日志就不再需要，其所占用的空间就可以被新的日志重用。所以，判断 Redo 日志可以被覆盖的依据是它对应的脏页是否被刷盘。

为此，InnoDB 提供一个全局变量 checkpoint_lsn，表示可被覆盖的日志量，或者说已被刷盘的日志量，其初始值自然也是 8704，凡是 LSN 小于该值的 Redo 日志都可以被覆盖。假设现在刷盘一个脏页，那么其对应 Redo 日志就可以被覆盖，checkpoint_lsn 将会根据脏页对应的 Redo 日志增值，这个过程称为"执行一次 checkpoint"。

执行一次 checkpoint 可以分为两个步骤：

* 计算 checkpoint_lsn 新值，其实就是获取 Flush 链表尾结点的 oldest_modification 属性；
* 将 checkpoint_lsn、对应 Redo 日志文件组偏移量，以及 checkpoint_no 写到 Redo 日志文件管理信息。

InnoDB 维护有一个变量记录系统做过多少次 checkpoint，称为 checkpoint_no，每做一次 checkpoint，这个变量就加 1。虽然每个 Redo 日志文件都有 4 个 block 管理信息，但是上述 checkpoint 信息只会被写到第一个日志文件。如果 checkpoint_no 是偶数，就把 checkpoint 信息写到 checkpoint1，否则写到 checkpoint2。

> 刷盘脏页的后台线程与执行 checkpoint 的线程不是同一个线程，所以 checkpoint_lsn 具有滞后性。

## 崩溃恢复过程

**确定恢复启点**

前面提到 checkpoint_lsn 前的 Redo 日志都可以被覆盖，因为这些日志对应的脏页已经被刷盘，所以不需要使用日志来恢复页面。Redo 日志文件有两个地方保存 checkpoint_lsn：checkpoint1 和 checkpoint2，InnoDB 将会选择 checkpoint_no 更大的那个，获得最新 checkpoint_lsn 和对应文件偏移量，以它作为恢复启点。

**确定恢复终点**

至于终点，InnoDB 会从 block 结构着手，前面提到 Redo 日志文件是顺序存储，只有前一个 block 写满才会继续写下一个 block，普通 block 的 header 部分有一个 LOG_BLOCK_HDR_DATA_LEN 属性，表示当前 block 已经使用了多少个字节，blcok 写满时值为 512，如果不为 512，说明这是最后一个 block，那它就是此次恢复的终点。

**日志使用优化**

确定需要使用的 Redo 日志范围之后，直接按序扫描即可，但 InnoDB 还有一些优化用于加快恢复速度：

* 使用哈希表

  可能有多条 Redo 日志记录同一个页面的修改，如果这些日志位置比较分散，按序执行的话同一个页面就需要反复打开和修改，这当然会影响性能。

  为此，根据 Redo 日志 space ID 和 page number 计算哈希值，把同一个页面的日志集中在一起，槽内日志按先后顺序链接。现在只需遍历哈希表，每个页面只用打开一次就能完全恢复。

* 跳过已经刷盘的页面

  刷盘和 checkpoint 异步执行，所以可能发生脏页已被刷盘，但是 checkpoint_lsn 没来得及同步，这时又怎么判断页面是否需要进行恢复呢？Index 页的 File Header 部分有一个属性 FIL_PAGE_LSN，表示最近一次修改该页的 MTR 的 LSN 值，其实就是控制块 newest_modification 属性。如果页面在最后一次 checkpoint 之后有被刷盘，它的 FIL_PAGE_LSN 应该大于 checkpoint_lsn 值，符合这种情况的页就不需使用那些 LSN 值小于 FIL_PAGE_LSN 的 Redo 日志，加快恢复速度。

# 撤销日志 undo

## 相关概念

**初步认识**

InnoDB 支持事务功能，事务需要满足原子性，又因为事务支持回滚操作，所以事务每次执行修改操作都需记下相应信息用于回滚恢复。比如，插入一条记录，那就记下这条记录的主键值，回滚时直接根据主键值删除这一条记录即可；更新一条记录，则记下更新列的原值，回滚时更新回来即可；删除一条记录，就记下这条记录的全部，回滚时重新插入这条记录即可。这些为了回滚而保存的数据称为 undo 日志。

**事务 ID**

事务分为只读事务和读写事务，只读事务不能对普通表进行增、删、改，但可以对临时表做增、删、改，通过以下语句可以开启一个读写事务：

```
START TRANSACTION [READ WRITE] 或 BEGIN
```

通过以下语句可以开启一个只读事务：

```
START TRANSACTION READ ONLY
```

事务如果在执行过程中对某个表执行了增、删、改操作，那么 InnoDB 将会为它分配一个唯一事务 ID。对于只读事务，仅当它第一次修改某个**用户创建的临时表**时才会为它分配一个事务 ID，对于读写事务，仅当它第一次修改某个表（用户表或临时表）时才会为它分配一个事务 ID。

事务 ID 只是一个数字，它的分配策略与 row_id 隐藏列相同：MySQL 维护有一个全局变量，每当需要时就把这个变量作为事务 ID 分配给事务，然后把变量自增 1，若变量值是 256 倍数，那就把它刷新到表空间的页号为 5 的页面的 Max Trx ID 属性，这个属性占 8 个字节。服务重启时会加载这个属性，将它加上 256 再赋给前边提到的全局变量。

**隐藏列 trx_id**

前边记录行格式有提到 row_id、trx_id、roll_pointer 这 3 个隐藏列，其中，row_id 是一定条件下自动生成的主键列，而 trx_id 表示最近一次改动当前记录的事务的事务 ID，至于 roll_pointer，后几节说。

## 日志格式

为了实现事务的原子性，InnoDB 增、删、改一条记录时都会先记下对应 undo 日志。通常，对一条记录做的一次修改对应一条 undo 日志，有些修改操作则对应两条 undo 日志。事务可以包含多个修改操作，所以单个事务可能对应多条 undo 日志，这些日志根据产生顺序从 0 开始编号，这个编号称为 undo no。这些 undo 日志会被存到 FIL_PAGE_UNDO_LOG 页面，这种页面从系统表空间或 undo 表空间申请。

### INSERT 操作 undo 日志

若要回滚插入一条记录的操作，只需对这条记录执行删除，因此插入操作对应 undo 日志只需记下这条记录的主键信息，这种 undo 日志的类型是 TRX_UNDO_INSERT_REC，以下是它的结构示意图。

> 注意，这里只会针对聚簇索引进行记录，至于二级索引，它们会在修改聚簇索引时连带修改。每个二级索引页面 Page Header 部分都有一个 PAGE_MAX_TRX_ID 属性，表示最近一次修改该页面的事务的事务 ID。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-fc9d7bca.jpg)

**隐藏列 roll_pointer**

最后一个隐藏列 roll_pointer，表示最近一次改动当前记录的事务的 undo 日志的指针，占用 7 个字节。

### DELETE 操作 undo 日志

事务对一条记录执行删除操作，整个删除的过程需要经历两个阶段：

* 第一阶段：把记录的 delete_mask 标识设为 1，其它不变，这个阶段称为 delete mark，被删记录在事务提交前都处于这个状态；设计这个中间状态，目的是为了实现 MVCC 功能。

* 第二阶段：把记录从普通链表移到垃圾链表头结点，调整页面一些信息，比如记录数量 PAGE_N_RECS、上次插入记录的位置 PAGE_LAST_INSERT、垃圾链表头结点 PAGE_FREE、页面可重用字节数 PAGE_GARBAGE 等等，这个阶段称为 purge。仅当第二阶段执行完毕，记录才算被删，它占用的空间才能被重新利用。

从上可知，事务提交之前被删记录将一直处于 delete mark 状态，事务提交之后自然不需回滚，InnoDB 为此设计了一种 TRX_UNDO_DEL_MARK_REC 类型 undo 日志，以下是它的结构示意图。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-1be054dc.jpg)

属性很多，但都比较简单直观，其中 old roll_pointer 属性是记录的前一条 undo 日志指针，通过这个属性可以把同一条记录的多个 undo 日志串联起来，这就是记录的**版本链**。索引列各列信息用于 purge 阶段真正删除，具体如何使用暂不深究，直觉应该与二级索引的修改有关。

### UPDATE 操作 undo 日志

事务对一条记录执行更新操作，针对是否有更新主键 undo 日志会有不同的处理方案。

**不更新主键**

对于不更新主键的情况，又需根据被更新的列占用的存储空间是否发生变化来分为两种情况：

* 就地更新（in-place update）

  对于被更新的**每个列**来说，如果更新后的列与更新前占用的存储空间都一样大，那就进行原地更新，直接在原记录的基础上修改对应列的值。

* 删除旧记录，插入新记录

  如果有任何一个被更新的列与更新前占用的存储空间大小不一致，那么就需要先把这条记录先从聚簇索引页面删除，然后使用更新后的列值创建一条新记录插入到页面。

  注意，这里的删除是真正的删除，而非 delete mark，用户线程需要同步完成 purge 阶段。

针对不更新主键的更新操作，InnoDB 设计了一种 TRX_UNDO_UPD_EXIST_REC 类型 undo 日志，以下是它的结构示意图。该种日志也有 old roll_pointer 属性，只有 INSERT 操作对应 undo 日志没有这个属性。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-8e39f841.jpg)

**更新主键**

聚簇索引是根据主键值的大小来组织记录，所以如果某条记录的主键被修改了，那么它在聚簇索引的位置可能需要变化以满足结构正确，针对这种情况，InnoDB 会进行两步处理：

* 首先，对旧记录执行 delete mark，这里不直接删除是因为可能有其它事务正在访问这条记录；
* 然后，使用更新后的列值创建一条新记录，把它插入到聚簇索引。

对于这种情况，旧记录执行 delete mark 之前，将会记录一条 TRX_UNDO_DEL_MARK_REC 日志，然后在插入新记录时，又会记录一条 TRX_UNDO_INSERT_REC 日志，这两日志类型已在前边介绍过了。

## 链表结构

写入 undo 日志的过程中会用到很多链表，这些链表都有相同的结点结构，如下所示。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-ceb4c1e8.jpg)

指定的表空间中，可以通过页号和页内偏移量来唯一定位一个结点的位置，这两信息相当于结点的指针，所以上面结构包含前一个结点和后一个结点的指针。

为了更好地管理链表，InnoDB 还提出了一个基结点的结构，这个结构记录了链表的头结点、尾结点以及链表长度信息，以下是它的结构示意图。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-7873d58b.jpg)

其实，这些都是 InnoDB 表空间的知识，这里只是简单复述。

## undo 页面结构

InnoDB 使用 FIL_PAGE_UNDO_LOG 页面存储 undo 日志，现在把这种页简称 undo 页，这种类型的页面的通用结构如下所示。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-b8ea8aeb.jpg)

Undo Page Header 是 undo 页特有部分，它的结构如下所示。属性 TRX_UNDO_PAGE_TYPE 指示本页用于存储哪种日志，值 TRX_UNDO_INSERT 表示存储 TRX_UNDO_INSERT_REC 类型日志，值 TRX_UNDO_UPDATE 表示存储其它类型日志。因为 INSERT 日志在事务提交后可以直接删除，而 UPDATE 日志因为 MVCC 需要保留，所以不同日志需要分开存储；TRX_UNDO_PAGE_START 是第一条日志的起始偏移量，TRX_UNDO_PAGE_FREE 则是最后一条日志的结束偏移量；TRX_UNDO_PAGE_NODE 是一个 List Node 结构，前面已经介绍过它的结构。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-c44289c9.jpg)

## undo 页面链表

### 基本概念

**单个事务的页面链表**

已经知道，单个事务可以产生很多 undo 日志，这些日志可能需要多个 undo 页面才能保存，而这些存储相同事务日志的 undo 页会通过页的 TRX_UNDO_PAGE_NODE 结构组成一个链表，称为 undo 页面链表。链表的第一个页称为 first undo page，其会额外保存一些管理信息，其它的页称为 normal undo page，只存 undo 日志。

事务可能混着执行 INSERT、DELETE、UPDATE 语句，这会产生不同类型 undo 日志，但是一个 undo 页面只能存储 INSERT 日志，或者 UPDATE 日志，所以一个事务可能需要两个 undo 页面链表来存储日志，其中一个称为 insert undo 链表，另一个称为 update undo 链表。

另外，InnoDB 规定对普通表和临时表的记录改动产生的 undo 日志需要分开存储，所以一个事务最多会需要 4 个 undo 页面链表。这些链表不会在事务一开始就产生，而是需要时才创建。

**多个事务的页面链表**

为了尽可能地提高 undo 日志的写入效率，不同事务在执行过程中产生的 undo 日志会被写入到不同的 undo 页面链表，也就是说，每个 undo 页面链表都专属某个特定事务。

### Segment Header

InnoDB 规定，每个 undo 页面链表都对应一个段，这种段称为 Undo Log Segment，链表的页都是从这个段里边申请。链表的第一个页会额外记录一些信息，对此 first undo page 有个 Undo Log Segment Header 结构，其中包含链表对应的段的 Segment Header 信息，以及其它一些段的相关信息，如下所示。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-dbd1b7ed.jpg)

以下说明 Undo Log Segment Header 结构各个属性的含义：

* TRX_UNDO_STATE：undo 页面链表的状态，它有以下可选值：
  * RX_UNDO_ACTIVE：活跃状态，说明正有一个事务在向该链表写入日志；
  * TRX_UNDO_CACHED：被缓存状态，这种链表等待被其它事务重用；
  * TRX_UNDO_TO_FREE：对于 insert undo 链表，如果它的事务提交之后，链表不能被重用，链表就处于这个状态；
  * TRX_UNDO_TO_PURGE：对于 update undo 链表，如果它的事务提交之后，链表不能被重用，链表就处于这个状态；
  * TRX_UNDO_PREPARED：用于存储 PREPARE  阶段的事务产生的日志，这个阶段与分布式事务有关。
* TRX_UNDO_LAST_LOG：该 undo 页面链表最后一个 Undo Log Header 的位置；
* TRX_UNDO_FSEG_HEADER：该 undo 页面链表对应的段的 Segment Header 结构；
* TRX_UNDO_PAGE_LIST：所属 undo 页面链表的基结点，这个结构前边也有介绍。

### Undo Log Header

InnoDB 向 undo 页面写入日志的方式很简单，就是一个挨着一个往里填，各个日志之间亲密无间，写完一个页面就从段里申请一个新页，将其插到 undo 页面链表然后继续写。

InnoDB 规定，同一个事务向一个 undo 页面链表写的日志属于一个组，每次写入一组日志都会先在日志前边填写组的一些属性，存放这些属性的地方称为 Undo Log Header。所以，undo 页面链表的第一个页在真正写入日志之前，都会填充 Undo Page Header 、Undo Log Segment Header 、Undo Log Header 这 3 个部分。

Undo Log Header 包括许多属性，以下列出并简单说明：

* TRX_UNDO_TRX_ID：产生本组 undo 日志的事务的 ID；
* TRX_UNDO_TRX_NO：事务提时生成的一个序号，越晚提交值越大；
* TRX_UNDO_DEL_MARKS：是否包含因为 delete mark 产生的日志；
* TRX_UNDO_LOG_START：该组第一个日志的页内偏移量；
* TRX_UNDO_DICT_TRANS：该组日志是否由于 DDL 语句而产生；
* TRX_UNDO_TABLE_ID：若上一个属性为真，这个属性就是操作的表的 table id；
* TRX_UNDO_NEXT_LOG：下一组 undo 日志在页面中开始的偏移量；
* TRX_UNDO_PREV_LOG：上一组 undo 日志在页面中开始的偏移量；
* TRX_UNDO_HISTORY_NODE：12 字节 List Node 结构，表示一个 History 链表结点。

通常一个 undo 页面链表只存储一个事务产生的一组 undo 日志，但在某些情况，在一个事务提交之后，后面事务会重用这个 undo 页面链表，这个链表就可能有多组日志，同时就有多个 Undo Log Header 结构。

## undo 页面重用

前面提到，为了提高并发性能 InnoDB 会为每个事务单独创建 undo 页面链表，但这有点浪费，因为有的事务可能只会产生几条 undo 日志，为它维护一个或多个完整链表有点得不偿失。针对这种情况，InnoDB 规定在一些特定情况，某些 undo 页面链表在事务提交之后可以被后面的事务重用。

以下是一个 undo 页面链表可以被重用的条件，需要同时满足：

* 链表只有一个 undo 页面，如果有较多页面，重用会导致许多无用页无法及时释放；
* 页面已经使用的空间小于整个页面 3/4，同理，如果有较多无用旧日志需要保留，那就得不偿失。

对于 insert undo 和 update undo 两种链表，它们的重用策略也不相同：

* insert undo 链表

  该链表只有 INSERT 日志，这种日志在事务提交之后可以被清除，新事务会直接覆盖旧日志来重用链表；

* update undo 链表

  在一个事务提交之后，它的 UPDATE 日志不能立即被删除，因为需要用于 MVCC 功能，所以如果这个链表被重用，新事务会在旧日志后边追加新日志来重用链表，这种情况链表就会有多组日志。

重用 undo 日志链表时，新的事务还需调整旧链表的一些信息，比如 Undo Page Header、Undo Log Segment Header、Undo Log Header 中的一些属性。

## 回滚段

### 基本概念

同一时刻系统可能有很多个 undo 页面链表，为了更好地管理这些链表，InnoDB 提供 Rollback Segment Header 页面，它会记录各个 undo 页面链表的第一个页的页号，这些页号称为 undo slot。

InnoDB 规定，每一个 Rollback Segment Header 页面都对应一个段，这种段称为 Rollback Segment，翻译过来就是回滚段，特别的是，回滚段都只有一个页。

以下列出 Rollback Segment Header 页面各个部分并简单说明：

* TRX_RSEG_MAX_SIZE：管理的所有 undo 页面链表的 undo 页面数量之和的最大值，默认 0xFFFFFFFE；
* TRX_RSEG_HISTORY_SIZE：History 链表的页面数量，这个链表 MVCC 章节介绍；
* TRX_RSEG_HISTORY：History 链表的基结点；
* TRX_RSEG_FSEG_HEADER：Segment Header 结构，10 字节，用于定位 INODE Entry 结构；
* TRX_RSEG_UNDO_SLOTS：各个 undo 链表 first undo page 页号集合，共有 1024 个 undo slot。

### 申请页面链表

初始还没有为任何事务分配任何 undo 页面链表，此时 Rollback Segment Header 页面的各个 undo slot 都是初始值 FIL_NULL（0xFFFFFFFF），表示 slot 不指向任何页面。

随着系统运行，逐渐会有事务执行需要分配 undo 页面链表，首先从回滚段第一个 undo slot 开始，检查它的值是否为 FIL_NULL，是则说明 slot 空闲，那就在表空间创建一个段，即 Undo Log Segment，再从段里面申请一个页作为 first undo page，最后把该 slot 设为刚申请页面的页号，这个 slot 便分配完成。如果不是 FIL_NULL，说明 slot 已被分配，继续尝试下一个 slot，如果 1024 个 slot 都已被分配，当前这个新事务将由于无法创建 undo 页面链表而回滚报错：Too many active concurrent transactions，用户看到这个信息可以选择重新执行事务。

当一个事务提交后，它占用的 undo slot 有 2 种命运：

* 若 slot 对应 undo 页面链表符合重用条件，这个 slot 将转为被缓存状态，链表 TRX_UNDO_STATE 属性会被设为 TRX_UNDO_CACHED 值。

  所有被缓存 slot 都会加入一个链表，根据对应 undo 页面链表的类型，相应加到不同链表，对于 insert undo 链表，slot 加到 insert undo cached 链表，对于 update undo 链表，则加到 update undo cached 链表。

  每个回滚段都有以上两个 cached 链表，现在新事务如需分配 undo slot，先从对应 cached 链表中找，如果找不到被缓存 undo slot，才会到回滚段页面中找。

* 若对应 undo 页面链表不符合重用条件，针对不同的链表类型会有不同的处理，对于 insert undo 链表，链表属性 TRX_UNDO_STATE 会被设为 TRX_UNDO_TO_FREE，然后把这个链表对应的段释放掉，最后把这个 slot 设为 FIL_NULL；对于 update undo 链表，链表属性 TRX_UNDO_STATE 会设为 TRX_UNDO_TO_PRUGE，再把 slot 设为 FIL_NULL，然后把本次事务写的一组 undo 日志放到 History 链表。

### 多个回滚段

单个回滚段只有 1024 个 undo slot，显然这个数量有点少，这会限制可以同时执行的事务的数量，为此，InnoDB 定义了 128 个回滚段。每个回滚段都对应一个 Rollback Segment Header 页面，这么多页面如何维护呢？

InnoDB 设计系统表空间第 5 号页面的某个区域包含 128 个 8 字节大小的格子，每个格子都有两个属性：

* Space ID：表空间 ID，4 字节；
* Page number：页号，4 字节。

每个格子相当于一个指针，指向某个表空间中的某个页面，这个页就是 Rollback Segment Header，从这里可以看出，不同回滚段可能分布在不同的表空间。

![](https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-fb2bd393.jpg)

### 回滚段分类

对回滚段进行编号，基于 0，这 128 个回滚段可以分为两类：

* 第 0 号、第 33～127 号回滚段属于一类，其中第 0 号回滚段必须在系统表空间，第 33～127 号既可以在系统表空间，也可以在配置的 undo 表空间，怎么配置后面再谈。如果一个事务由于对普通表的记录做了改动而需要分配 undo 页面链表，必须从这一类的段中分配 undo slot。

* 第 1～32 号回滚段属于一类，这些回滚段必须在临时表空间，如果一个事务由于对临时表的记录做了改动而需要分配 undo 页面链表，必须从这一类的段中分配 undo slot。

可以发现，假如一个事务同时对普通表和临时表的记录做了改动，那就需要为这个事务分配两个回滚段，然后分别到这两个回滚段中分配 undo slot。

为什么要针对普通表和临时表划分不同类的回滚段呢？说到底 undo 页面也只是一个普通的页面，我们知道在修改页面之前一定要先记录 Redo 日志，这样系统在崩溃重启之后才能恢复到之前的状态。向 undo 页面写入日志本身也是一个写页面的过程，所以对 undo 页面做的任何改动都会记录相应 Redo 日志。但是，临时表只在系统运行过程中有效，重启后临时表都不存在了，自然没有必要对临时表记录 Redo 日志。划分类别之后，对临时表的回滚段中的 undo 页面所做的改动，不会记录任何 Redo 日志，普通表的回滚段照旧。

### 回滚段配置

**回滚段数量**

前面提到系统总共有 128 个回滚段，其实这只是默认值，可以通过配置参数 innodb_rollback_segments 修改回滚段数量。但是，无论如何修改，针对临时表的回滚段永远有 32 个，就算值小于 32 也不会改变，这只会造成没有针对普通表的回滚段。

**配置 undo 表空间**

默认情况，针对普通表的回滚段都被分配到系统表空间，其中第 0 号段永远在系统表空间，而第 33~127 号段可以通过配置放到自定义 undo 表空间中。

这些配置只能在系统初始化时使用，即创建数据目录时，初始化完成后不能再次更改，以下是相关配置参数：

* innodb_undo_directory：指定 undo 表空间所在目录，默认就是数据目录；
* innodb_undo_tablespaces：指定 undo 表空间数量，默认 0，表示不创建任何 undo 表空间。

配置之后，第 33~127 号回滚段将会平均分布到这些 undo 表空间，另外，第 0 号回滚段将处于不可用状态。

## 崩溃恢复应用

数据库的崩溃恢复存在一个问题：重启过程中，数据库根据 Redo 日志将各个页面恢复到之前的状态，但是，可能存在未提交事务写的 Redo 日志被刷盘的情况，那这些事务所做的修改也会被恢复。

为了保证事务的原子性，需要在重启时把这些未提交的事务回滚，问题是如何找出未提交的事务呢？

通过系统表空间的第 5 号页定位到 128 个回滚段的位置，首先找出所有值不为 FIL_NULL 的 undo slot，每个 slot 对应一个 undo 页面链表，接着检查这些链表的第一个页的 Undo Log Segment Header 中的 TRX_UNDO_STATE 属性，如果值为 TRX_UNDO_STATE，表示崩溃之前有一个活跃的事务正在向该链表写入 undo 日志。然后再在 Segment Header 中找到 TRX_UNDO_LAST_LOG 属性，定位最后一个 Undo Log Header 位置，从该结构可以找到对应事务的事务 ID，这就是那个没来得及提交的事务。最后根据找出的事务 ID，将对应事务对页面所做的修改进行回滚，保证事务的原子性。

# 版本镜像 MVCC

对于一个数据库服务，可以有多个客户端与之连接，每个连接都称为一个会话。客户端能在自己的会话中向数据库发送请求语句，这个语句或许是某个事务的一部分，所以服务器可能要同时处理多个事务。事务具有隔离性，理论上在某个事务访问某个数据时，其它事务应该排队，当该事务提交之后，其它事务才能继续访问这个数据。这样子太影响性能，如何既保持事务的隔离性，又能让服务器有较高处理多个同时访问相同数据的事务的能力，鱼与熊掌不可兼得，只能舍弃一部分隔离性来获取并发性能。

## 事务隔离级别

### 各种并发问题

根据可能导致一致性问题的严重程度，排序以下现象：脏写 > 脏读 > 不可重复读 > 幻读

**脏写（ Dirty Write ）**

某个事务修改了另一个未提交事务修改过的数据

**脏读（ Dirty Read ）**

某个事务读到了另一个未提交事务修改过的数据

**不可重复读（Non-Repeatable Read）**

某个事务读了某个数据，然后这个数据被另一个事务修改并提交，原来事务再次读取数据获得一个不同的值。

**幻读（Phantom）**

某个事务根据某些条件查出一些记录，然后另一个事务向该表写入了符合这些条件的记录，原来事务根据相同条件再次查询获得一个不同的数据集，这里的写入包括 INSERT、DELETE 和 UPDATE 操作。

### 配置隔离级别

**标准隔离级别**

前面提到，舍弃一部分隔离性换取并发执行性能，为此设计了一个 SQL 标准，包含 4 个隔离级别，级别越低就越容易发生越严重的问题。

| 隔离级别                  | 脏读   | 不可重复读 | 幻读   |
| ------------------------- | ------ | ---------- | ------ |
| READ UNCOMMITTED 未提交读 | 可能   | 可能       | 可能   |
| READ COMMITTED 已提交读   | 不可能 | 可能       | 可能   |
| REPEATABLE READ 可重复读  | 不可能 | 不可能     | 可能   |
| SERIALIZABLE 可串行化     | 不可能 | 不可能     | 不可能 |

没有提及脏页，因为这个问题实在太过严重，无论哪种隔离级别都不允许脏写发生，实现方式是事务在更新一条记录时会对它加锁，禁止其它事务修改这条记录。

**MySQL 隔离级别**

各个数据库厂商可以自由选择如何实现 SQL 标准的 4 种隔离级别，比如 Oracle 就只支持 SERIALIZABLE 和 READ COMMITTED 两种级别，MySQL 虽然支持 4 种级别，但与定义有一些差异，MySQL 的 REPEATABLE READ 级别可以很大程度禁止幻读，原理后面再说。

MySQL 默认隔离级别是 REPEATABLE READ，可以通过配置参数修改默认的隔离级别

```
transaction-isolation=SERIALIZABLE
```

同时还可以在运行时通过以下语句修改事务的隔离级别

```
SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level
```

以下是各个关键字的说明：

* GLOBAL：全局范围，对当前语句之后产生的所有会话有效，但对已经存在的会话无效；
* SESSION：会话范围，对当前会话的所有后续事务有效，这个语句可以在事务中间执行；
* 没有关键字：只对当前会话的下一个开启的事务有效，这个语句不能在事务中间执行。

通过系统变量，查看当前会话的隔离级别，其实还能通过系统变量来修改隔离级别，但有点复杂，暂不深究。

```
SELECT @@transaction_isolation;
```

## MVCC 原理

### 记录的版本链

已经知道，每一条聚簇索引记录都有以下两个隐藏列：

* trx_id：最近一次改动当前记录的事务的事务 ID；

* roll_pointer：最近一次改动当前记录的事务的 undo 日志的指针。

另外，UPDATE 和 DELETE 操作 undo 日志都有一个 old roll_pointer 属性，从 trx_id 隐藏列开始，记录所有版本将会串成一个链表，这就是记录的版本链。InnoDB 利用这个版本链来控制并发事务访问相同记录时的行为，这种机制称为多版本并发控制（Multi-Version Concurrency Control，MVCC）。

INSERT 操作 undo 日志没有 old roll_pointer 属性，因为新插入的记录不会有更早的版本，这种记录自然不会有版本链，因此 INSERT 操作 undo 日志也不会在事务提交后保留。

### 视图 ReadView

因为 READ UNCOMMITTED 隔离级别的事务可以读到未提交事务修改过的记录，那就直接读取记录的最新版本即聚簇索引即可；对于 SERIALIZABLE 隔离级别的事务，InnoDB 规定使用加锁方式来**访问**记录，这能保证访问相同数据的事务串行化执行；对于 READ COMMITTED 和 REPEATABLE READ 隔离级别的事务，需要保证读到已提交事务修改过的记录，但不读未提交事务修改过的记录，为此提出 ReadView 概念，该结构有 4 个重要属性：

* m_ids：生成 ReadView 时系统中活跃的读写事务的事务 ID 列表；
* min_trx_id：m_ids 列表中最小的事务 ID；

* max_trx_id：生成 ReadView 时系统应该分配给下一个事务的事务 ID；
* creator_trx_id：生成当前 ReadView 的事务的事务 ID。

假如一个事务建有 ReadView 结构，它在访问某条记录时将按以下步骤判断哪个版本对自己可见：

* 如果版本 trx_id 属性与 ReadView 的 creator_trx_id 相等，说明这个版本由当前事务改动而生成，所以它可以被当前事务访问；

* 如果版本 trx_id 属性小于 ReadView 的 min_trx_id，说明生成这个版本的事务在当前事务开启前提交，所以它可以被当前事务访问；
* 如果版本 trx_id 属性大于 ReadView 的 max_trx_id，说明生成这个版本的事务在当前事务开启后开启，所以它不能被当前事务访问；
* 如果版本 trx_id 属性在 ReadView 的 min_trx_id 和 max_trx_id 之间，需要判断一下 trx_id 是否处于 m_ids 列表当中，如果是，说明当前事务开启时生成这个版本的事务还在活跃，这个版本不能访问；如果否，说明生成这个版本的事务已经提交，这个版本可以被访问。

假如某个版本的数据对当前事务不可见，那就顺着版本链找到下一个版本，继续按照上边的步骤判断可见性，直到最后一个版本，如果仍然不可见，那就意味着这条记录对该事务不可见，查询结果就不包含这条记录。

MySQL 的 READ COMMITTED 和 REPEATABLE READ 都会使用 ReadView 实现隔离性，它们的区别是 ReadView 创建的时机不同：

* READ COMMITTED：每次查询开始时都会生成一个独立 ReadView，很明显有不可重复读、幻读现象；

* REPEATABLE READ：事务只会在第一次查询时生成一个 ReadView，自己模拟一次发现可以防止幻读；

通过这里的学习，可以理解为什么要有 delete mark 中间状态，直接彻底删除会造成幻读、不可重复读。

### 辅助索引使用 MVCC

只有聚簇索引的记录才有 trx_id 和 roll_pointer 两隐藏列，如果某个查询使用二级索引执行，那么它该如果判断版本可见性呢？

二级索引 Page Header 部分有一个 PAGE_MAX_TRX_ID 属性，每当对二级索引页面增删改，如果执行该操作的事务的事务 ID 大于这个属性，就把事务 ID 赋给这个属性。所以，属性  PAGE_MAX_TRX_ID  表示修改该页面的最大事务 ID。当 SELECT 访问某个二级索引，首先会查看一下 ReadView 的 min_trx_id 是否大于 PAGE_MAX_TRX_ID 属性，如果是，说明页面的所有记录对该 ReadView 可见，如果否就执行下一个步骤；

利用二级索引的主键值进行回表操作，找到聚簇索引记录，然后按照步骤找到该记录可见的第一个可见版本，然后检查这个版本相应的二级索引列的值是否与回表时使用的值相等，如果是，说明这个版本可见，否则的话跳过这条记录，当然，即使可见，还需执行查询语句的其它条件，如果有的话。

注意，只有在进行普通 SELECT 查询时 MVCC 才会生效，目前学习的所有 SELECT 语句都是普通查询，而不普通查询会在锁的章节介绍。

### 删除撤销日志 Purge

**数据积累**

每个事务写的一组 undo 日志都以一个 Undo Log Header 开头，这个结构包含一个 TRX_UNDO_HISTORY_NODE 属性，表示一个 History 链表结点。当一个事务提交后，将把它生成的那组 update undo 日志插到 History 链表头部，至于 insert undo 日志，则直接删除。

每个回滚段都有且仅有一个 Rollback Segment Header 页面，这个页面有两个属性：

* TRX_RSEG_HISTORY：History 链表的基结点；
* TRX_RSEG_HISTORY_SIZE：History 链表占用的页面数量。

所以，每个回滚段都有一个 History 链表，链表的一个结点是已提交事务生成的一组 undo 日志。系统可能存在很多个回滚段，这也意味存在很多 History 链表。那么，这些 History 链表中的结点，即 undo 日志什么时候才会被释放呢？总不能一直存在吧！

另外，delete mark 操作仅会在记录上打一个删除标记，Undo Log Header 有一个属性 TRX_UNDO_DEL_MARKS 标记本组 undo 日志是否包含由于 delete mark 产生的日志，这种标记为删除的**记录**又该何时清理呢？

**日志删除**

为了节省内存空间，InnoDB 将会选一个时机把 update undo 日志和标记为删除的记录彻底删除，这个清理操作称为 purge，那么执行的时机到底是什么时候呢？

其实 update undo 日志和 delete mark 都是为了 MVCC 而保留，所以只要系统中最早产生的那个 ReadView 不再访问它们，它们就没有必要存在，可以删除。何时 ReadView 肯定不会访问某个事务 undo 日志呢？其实，只要能够确定生成 ReadView 之前某个事务已经提交，这个 ReadView 就绝对不会访问该事务 undo 日志。

删除 update undo 日志和 delete mark 记录之前，InnoDB 会持续地做两件事：

* 事务提交的时候会为它生成一个 no 值，表示事务的提交顺序，越晚提交值越大，Undo Log Header 有一个属性 TRX_UNDO_TRX_NO 就是用来存放 no 值。History 链表按照事务提交顺序排列各组 undo 日志，所以可以说 History 链表按照 no 值排列各组 undo 日志。

* ReadView 还有一个事务 no 属性，生成 ReadView 时会把当前系统中最大事务 no 值加 1 赋给这个属性。

InnoDB 把系统中所有 ReadView 按创建时间连成一个链表，后台有一个线程专门负责执行 purge，当执行 purge 时，将从链表取出最早那个 ReadView，如果系统此时没有 ReadView，就当场创建一个，然后用它把各个回滚段 History 链表中所有事务 no 值小于最早 ReadView 的 no 值的日志删除，如果有去除 delete mark 日志，还需把对应的记录彻底删除。这样，就能释放无用的日志和记录占用的空间。

有个问题，系统根据最早 ReadView 决定 purge 过程删除哪些 insert undo 日志和 delete mark 记录，那么如果某个事务使用 REPEATABLE READ 隔离级别，它会一直复用初始创建的那个 ReadView，如果事务运行很久，这个 ReadView 就会一直不释放，系统 update undo 和 delete mark 记录会越来越多，表空间文件会越来越大，记录版本链也会越来越长，影响系统性能。

# InnoDB 锁

# 单表访问方法

已知 MySQL 有一个优化器模块，查询语句经过语法解析后被交给优化器处理，生成一个执行计划，其中包含应该使用哪些索引，表之间的连接顺序等。最后，按照计划调用存储引擎接口返回数据。查询优化内容太多，这里先来了解 MySQL 怎么执行单表查询，即 FROM 子句只有一个表。

## 访问方法

查询语句本质是一种声明式的语法，它只告诉数据库要获取什么样的数据，至于如何实现则毫不关心。MySQL 把执行查询语句的方式称为访问方法（access method）。同一个查询可以使用多种不同的访问方法执行，虽然结果相同，但执行成本可能差距很大。

假设有一个表 *single_table*，主键 *id*，二级索引 *key1*、*key3*，唯一二级索引 *key2*，联合索引 *key_part1* 、*key_part2* 、*key_part3*。

### const

通过等值比较主键或者唯一二级索列与一个常数，以此定位**一条**记录，这种访问方法称为 const。如果索引由多个列组成，则每个索引列都需与常数进行等值比较。

```
SELECT * FROM single_table WHERE key2 = 3841;
```

对于唯一二级索引，如果比较的值是 NULL，则不能使用 const，至多使用 ref 方法。

```
SELECT * FROM single_table WHERE key2 IS NULL;
```

该访问方法的特点是每个查询最多只有一条记录符合条件。

### ref

通过等值比较二级索引与一个常数，以此定位记录，对应**一个**单点扫描区间，每查到一条满足条件的索引记录就要进行回表，这种访问方法称为 ref。对于联合索引，需要满足最左边连续的列与常数进行等值比较。

```
SELECT * FROM single_demo WHERE key1 = 'abc';
```

该访问方法的特点是一个单点扫描，其中可能有多条满足条件的记录。

### ref_or_null

除了等值比较二级索引与一个常数，额外判断是否为 NULL，对应一个单点扫描区间和 `[NULL,NULL]`，索引会把 NULL 值记录存到前面。

```
SELECT * FROM single_demo WHERE key1 = 'abc' OR key1 IS NULL;
```

### range

普通地使用索引执行查询，对应多个单点扫描区间或范围扫描区间，扫描区间 `[-∞,+∞]` 不是 range 方法。

### index

全表扫描二级索引，且不用进行回表，成本比全表扫描聚簇索引小的多。

```
SELECT key_part1, key_part2, key_part3 FROM single_table WHERE key_part2 = 'abc';
```

全表扫描 InnoDB 表时，如果有 "GROUP BY 主键" 语句，那么该次执行也被认为使用 index 方法。

### all

全表扫描，对 InnoDB 表来说，就是从头到尾遍历所有聚簇索引记录。

## 索引合并

使用索引来减少需要扫描的记录数量时，往往只会为单个索引形成扫描区间，而且，等值查找通常比范围查找需要扫描的记录数更少，但这并不总是成立，可能存在很多值相同的记录。

### Intersection 合并

存在一些特殊情况，MySQL 会为多个索引生成扫描区间。以下语句，单独使用 key1 或 key2 索引，都有可能发生大量无效回表，因为回表后还要判断是否满足另一个查询条件。

```
SELECT * FROM single_table WHERE key1 = 'a' AND key3 = 'b';
```

为此，设计 MySQL 分别对 key1 和 key2 索引进行查找，然后取两个索引的结果集的主键交集，这些主键的对应记录同时满足两个查询条件，再进行回表。这种方案叫做 Intersection 合并，能够避免无效回表。

使用 Intersection 合并需要满足一个条件：从索引中获取的索引记录集合，必须按照主键值排列。因为对有序集取交集更简单，且对连续的主键值回表不会造成大量随机 IO，提高效率。

### Union 合并

以下语句使用 OR 连接两个查询条件，单独使用 key1 或 key2 索引，都要进行全表扫描。

```
SELECT * FROM single_table WHERE key1 = 'a' OR key3 = 'b';
```

为此，设计 MySQL 分别对 key1 和 key2 索引进行查找，然后取两个索引的结果集的主键并集，这些是所有满足条件的记录的主键集合，再进行回表。这种方案叫做 Union 合并，能够避免无效回表。

使用 Union 合并同样需要满足从各索引获取的记录按主键值排列，原因与 Intersection 合并相同。

### Sort-Union 合并

Union 合并的条件可能有点苛刻，很多时候都无法根据条件从索引获取按主键排序的结果集。这时，MySQL 先把两个索引的结果集按主键排序，然后就能进行 Union 合并。相比 Union 合并，多了一步排序操作，这在很多时候仍然值得。注意，MySQL 没有实现 Sort-Intersection 合并。

# 表连接的原理

## 认识连接

### 连接的本质

表连接就是把两个表的记录两两配对，形成一个新表，然后根据条件筛选行和列，最后得到目标数据。结果表如果包含所有配对，那它就是两个表的笛卡尔积，如下所示。

<img src="https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-00f96141.jpg" style="zoom: 50%;" />

### 连接的过程

如果需要，可以连接任意数量个表，但是如果没有限制条件，这些表连接起来产生的笛卡尔积会非常大。3 个 300 行记录的表的笛卡尔积就有 100,00,00 行数据。所以，连接的时候设置过滤条件很有必要。

连接查询中的过滤条件可以分为两种：

* 只涉及单表的过滤条件，就是查询条件，比如 t1.m1 > 1；
* 涉及两个表的过滤条件，比如 t1.m1 = t2.m2、t1.n1 > t2.n2；

以下连接查询语句，有 3 个过滤条件：t1.m1 > 1、t1.m1 = t2.m2、t2.n2 < 'd'。

```
SELECT * FROM t1, t2 WHERE t1.m1 > 1 AND t1.m1 = t2.m2 AND t2.n2 < 'd';
```

这个连接查询的执行，大致步骤如下：

* 确认第一个查询的表，称为驱动表，对其进行单表查询。假设以 t1 为驱动表，查询条件 t1.m1 > 1；

* 每从驱动表得到一行记录，就用该记录转换涉及两表的过滤条件为只与 t2 相关的条件，然后使用所有 t2 过滤条件对 t2 单表查询，再把结果的记录分别与这个驱动表的记录连接，得到一部分结果。

* 重复第二步，直到驱动表查询结束，便得到此次连接查询的所有结果。如下所示。

<img src="https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-8abfd35e.jpg" style="zoom: 80%;" />

由此可知，驱动表只会访问一次，而被驱动表的访问次数，取决于驱动表的查询结果。

### 内连接和外连接

#### 认识内/外连接

普通的连接查询，MySQL 根据驱动表的结果匹配被驱动表的记录，如果想要即使被驱动表没有匹配的记录时仍将驱动表的记录加入到结果集，就需要使用外连接。外连接正是为了解决这个问题而提出。

* 内连接：仅当驱动表的记录在被驱动表有匹配记录时，才会加入结果集，普通连接都是内连接；
* 外连接：驱动表的记录全部都会加入结果集，即使在被驱动表没有匹配的记录。

MySQL 外连接分为左外连接和右外连接，它们的区别是选择左侧或右侧的表作为驱动表，所以说外连接的驱动表需要手动指定，而内连接的驱动表由 MySQL 根据成本决定。

#### ON 和 WHERE

对于外连接来说，可能并非所有驱动表的记录都想加到结果集，如何进行筛选？

MySQL 为此提出 ON 子句过滤条件。驱动表的记录即使在被驱动表找不到满足 ON 子句条件的记录，这条记录仍会添加到结果集，对应被驱动表记录的各个字段使用 NULL 填充。至于 WHERE，无论内连接或外连接，凡是不符合过滤条件的记录都不会添加到结果集。

另外，外连接必须使用 ON 子句指出表之间的连接条件。

#### 内/外连接语法

关键字 LEFT JOIN 左边的表是驱动表，即 t1。

```
SELECT * FROM t1 LEFT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];
```

关键字 RIGHT JOIN 右边的表是驱动表，即 t2。

```
SELECT * FROM t1 RIGHT [OUTER] JOIN t2 ON 连接条件 [WHERE 普通过滤条件];
```

对于内连接，ON 条件与 WHERE 条件作用相同，需要连接的表放到 FROM 子句就行。

```
SELECT * FROM t1 [INNER | CROSS] JOIN t2 [ON 连接条件] [WHERE 普通过滤条件];
```

## 连接原理

### 嵌套循环连接

已经知道，连接查询只访问一次驱动表，被驱动表的访问次数取决于驱动表的查询结果。若有三个表，就把前两个表的结果集作为新的驱动表，重复连接。这就像一个嵌套循环，有多少个驱动表，就有多少层循环，所以称为嵌套循环连接。这是最简单且效率最低的连接算法。

### 索引加快连接

驱动表会被执行一次单表查询，被驱动表会被执行若干次单表查询。因为每次访问被驱动表时，涉及两表的过滤条件中，那些驱动表的字段的值都已确定，所以访问被驱动表可以看作一次单表查询。基于单表查询知识，可以对被驱动表的字段建立索引，加快检索速度。

以下连接查询语句，假设 t1 为驱动表，t2 为被驱动表。如果对 t2.m2 字段建立索引，那么每次访问 t2 表，这次单表访问就有可能使用 ref 访问方法，因为这时 "t1.m1 = t2.m2" 等于 "常数 = t2.m2"。

```
SELECT * FROM t1, t2 WHERE t1.m1 > 1 AND t1.m1 = t2.m2;
```

连接查询有个特殊情况，如果被驱动表使用主键或者唯一二级索引与常数进行等值比较来定位一个记录，这种方法应该称为 eq_ref 而非 const。

### 基于块的嵌套循环

如果被驱动表数据量很大且每次都要进行全表扫描，会使 MySQL 反复从磁盘读取被驱动表。MySQL 每次获得驱动表的记录将不再立即访问被驱动表，而是把结果暂时放到 Join Buffer 连接缓冲区，然后再访问被驱动表进行批量匹配，这样做可以减少被驱动表的访问次数，称为基于块的嵌套循环连接。

最好的情况是 Join Buffer 大到足够存放所有驱动表的结果，这样只需访问一次被驱动表。

<img src="https://images-1305875271.cos.ap-chengdu.myqcloud.com/mysql-9ffc4d9e.jpg" style="zoom: 80%;" />

通过启动参数或者系统变量 join_buffer_size 设置 Join Buffer 大小，默认 262144 字节，即 256 KB。尽管有连接缓冲区，但最好还是使用索引来优化被驱动表的查询，比较内存很宝贵。

另外，需要注意，只有查询列表中的列和过滤条件中的列才会被放到 Join Buffer。所以，最好不要把 * 放在查询列表，它的坏处远不止这一个。
